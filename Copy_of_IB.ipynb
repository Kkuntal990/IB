{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of IB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kkuntal990/IB/blob/master/Copy_of_IB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFTXit79QyVn",
        "outputId": "02757ac3-7005-4750-ce46-73d8fc5fc35f"
      },
      "source": [
        "!pip install cleverhans"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cleverhans\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/a0/f0b4386b719f343c4ed3e13cd7792a7a7a4674566ca9b2b34a09b7424220/cleverhans-3.0.1-py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 5.5MB/s \n",
            "\u001b[?25hCollecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 13.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-probability in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.12.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from cleverhans) (3.2.2)\n",
            "Collecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/cc/227251b1471f129bc35e966bb0fceb005969023926d744139642d847b7ae/pycodestyle-2.7.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hCollecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.19.5)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (0.3.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (0.1.5)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBXDPxVXYwrD"
      },
      "source": [
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#import plotcm\n",
        "import sys\n",
        "import tensorflow.keras as keras\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import Reshape, Dense, Dropout, Activation, Flatten, Lambda\n",
        "import tensorflow.keras.models as models\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UTbXN6Zbkf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d2343aa-0048-4273-a0c6-69218f21b1dc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXDfrpJQaWj1"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/IB/RML2016.10a_dict.dat\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JQj5IZgYx-u"
      },
      "source": [
        "#import cPickle\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "sys.path.append('../confusion')\n",
        "\n",
        "name = 'CNN2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm0o0AKrYund"
      },
      "source": [
        "with open(\"RML2016.10a_dict.dat\", 'rb') as xd1:  \n",
        "    Xd = pickle.load(xd1, encoding='latin1')  # , encoding='latin1'\n",
        "snrs, mods = map(lambda j: sorted(\n",
        "    list(set(map(lambda x: x[j], Xd.keys())))), [1, 0])\n",
        "X = []\n",
        "lbl = []\n",
        "SNR = []\n",
        " \n",
        "for mod in mods:\n",
        "    for snr in snrs:\n",
        "        SNR.append(snr)\n",
        "        X.append(Xd[(mod, snr)])\n",
        "        for i in range(Xd[(mod, snr)].shape[0]):\n",
        "            lbl.append((mod, snr))\n",
        "X = np.vstack(X)\n",
        "# %%\n",
        "np.random.seed(2016)  \n",
        "n_examples = X.shape[0]\n",
        "n_train = n_examples * 0.5  # ĺŻšĺ\n",
        "train_idx = np.random.choice(\n",
        "    range(0, n_examples), size=int(n_train), replace=False)\n",
        "test_idx = list(set(range(0, n_examples)) - set(train_idx))  # label\n",
        "test_idx2 = []\n",
        "X_train = X[train_idx]\n",
        "for i in test_idx:\n",
        "    if SNR[i//1000] >= 0:\n",
        "        test_idx2.append(i)\n",
        " \n",
        "X_test = X[test_idx2]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "AcioyKhIBv9_",
        "outputId": "aa5cf72e-d630-4974-effd-1f2282788eb3"
      },
      "source": [
        "ii = np.random.randint(0,X_train.shape[0])\n",
        "print(ii)\n",
        "t = np.arange(X_train.shape[2])\n",
        "plt.plot(t, X_train[i, 0, :])\n",
        "plt.plot(t, X_train[i, 1, :])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzrJmCqJY5QA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ad8f129-73db-43ea-e73a-c3cbe70d600a"
      },
      "source": [
        "def to_onehot(yy):\n",
        "    yy1 = np.zeros([len(yy), max(yy) + 1])\n",
        "    yy1[np.arange(len(yy)), yy] = 1\n",
        "    return yy1\n",
        "\n",
        "\n",
        "trainy = list(map(lambda x: mods.index(lbl[x][0]), train_idx))\n",
        "Y_train = to_onehot(trainy)\n",
        "Y_test = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), test_idx2)))\n",
        "# %%\n",
        "in_shp = list(X_train.shape[1:])\n",
        "print(X_train.shape, X_test.shape)\n",
        "print(Y_train.shape, Y_test.shape)\n",
        "classes = mods\n",
        "print(in_shp)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(110000, 2, 128) (55027, 2, 128)\n",
            "(110000, 11) (55027, 11)\n",
            "[2, 128]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JzdfIa145yi"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow_probability import distributions as ds\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MUDQtBfZGh8"
      },
      "source": [
        "def sample_z(args):\n",
        "  mu, sigma = args\n",
        "  batch = K.shape(mu)[0]\n",
        "  dim = K.int_shape(mu)[1]\n",
        "  eps = K.random_normal(shape=(batch, dim))\n",
        "  return mu + K.log(1 + K.exp(sigma - 5.0)) * eps\n",
        "\n",
        "BETA = 2*1e-3\n",
        "prior = ds.Normal(0.0, 1.0)\n",
        "dr = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tlzJUyF1Ffl"
      },
      "source": [
        "class VAE(keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        inp = keras.Input(shape=(2,128,))\n",
        "        x = Reshape(target_shape=(2,128,1,))(inp)\n",
        "        x = ZeroPadding2D((0,2), data_format=\"channels_first\")(x)\n",
        "        x = Conv2D(256, (1, 3), padding='valid', activation=\"relu\", name=\"conv1\",kernel_initializer='glorot_uniform')(x)\n",
        "        x = Dropout(dr)(x)\n",
        "        x = ZeroPadding2D((0, 2), data_format=\"channels_first\")(x)\n",
        "        x = Conv2D(80, (2, 3), padding=\"valid\", activation=\"relu\", name=\"conv2\",kernel_initializer='glorot_uniform')(x)\n",
        "        x = Dropout(dr)(x)\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(512, activation='relu', name=\"mu\",kernel_initializer='he_normal')(x)\n",
        "        '''\n",
        "        mu = Dense(128, activation='relu', name=\"mu\")(x)\n",
        "        mu = Dropout(dr)(mu)\n",
        "\n",
        "        sigma = Dense(128, activation='relu', name=\"sigma\")(x)\n",
        "        sigma = Dropout(dr)(sigma)\n",
        "        '''\n",
        "        mu, sigma = x[:, :256], x[:, 256:]\n",
        "        #z = keras.layers.Lambda(sample_z, output_shape=(256, ), name='z')([mu, sigma])\n",
        "        encoder = keras.Model(inp, [mu,sigma], name=\"encoder\")\n",
        "        self.encoder = encoder\n",
        "        z = keras.Input(shape=(256,))\n",
        "        y = Dense(len(classes), name=\"dense3\", activation='relu',kernel_initializer='he_normal')(z)\n",
        "        decoder = keras.Model(z,y, name=\"decoder\")\n",
        "        self.decoder = decoder\n",
        "        self.encoder.summary()\n",
        "        self.decoder.summary()\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.val_loss_tracker = keras.metrics.Mean(name=\"val_loss\")\n",
        "        self.class_loss_tracker = keras.metrics.Mean(\n",
        "             name=\"class_loss\"\n",
        "         )\n",
        "        self.info_loss_tracker = keras.metrics.Mean(name=\"info_loss\")\n",
        "        self.IZY_bound_tracker = keras.metrics.Mean(name=\"IZY_bound\")\n",
        "        self.IZX_bound_tracker = keras.metrics.Mean(name=\"IZX_bound\")\n",
        "        self.train_acc_tracker = keras.metrics.Mean(name=\"Training accuracy\")\n",
        "        self.val_acc_tracker = keras.metrics.Mean(name=\"validation accuracy\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.class_loss_tracker,\n",
        "            self.info_loss_tracker,\n",
        "            self.total_loss_tracker,\n",
        "            self.IZY_bound_tracker,\n",
        "            self.IZX_bound_tracker\n",
        "            ,self.train_acc_tracker\n",
        "        ]\n",
        "\n",
        "    def call(self, data):\n",
        "      mu,sigma = self.encoder(data)\n",
        "      sigma = tf.math.softplus(sigma-5.0)\n",
        "      z_dist = ds.Normal(mu, sigma)\n",
        "      z = z_dist.sample()\n",
        "      y = self.decoder(z)\n",
        "      return tf.nn.softmax(y)\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, inp):\n",
        "        data, y_true = inp\n",
        "        with tf.GradientTape() as tape:\n",
        "            mu,sigma = self.encoder(data)\n",
        "            sigma = tf.math.softplus(sigma-5.0)\n",
        "            z_dist = ds.Normal(mu, sigma)\n",
        "            z = z_dist.sample()\n",
        "            y = self.decoder(z)\n",
        "            \n",
        "          \n",
        "            info_loss = tf.reduce_sum(tf.reduce_mean(ds.kl_divergence(z_dist, prior), 0)) /math.log(2)\n",
        "            class_loss = tf.compat.v1.losses.softmax_cross_entropy(logits=y, onehot_labels=y_true)\n",
        "            total_loss =  class_loss + BETA*info_loss\n",
        "        training_acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y, 1), tf.argmax(y_true, axis=1)), tf.float32))\n",
        "        IZY_bound =  math.log(10, 2) - class_loss\n",
        "        IZX_bound = info_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.class_loss_tracker.update_state(class_loss)\n",
        "        self.info_loss_tracker.update_state(info_loss)\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.IZY_bound_tracker.update_state(IZY_bound)\n",
        "        self.IZX_bound_tracker.update_state(IZX_bound)\n",
        "        self.train_acc_tracker.update_state(training_acc)\n",
        "        \n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"info_loss\": self.info_loss_tracker.result(),\n",
        "            \"class_loss\": self.class_loss_tracker.result(),\n",
        "            \"IZY_bound\" : self.IZY_bound_tracker.result(),\n",
        "            \"IZX_bound\" : self.IZX_bound_tracker.result()\n",
        "            ,\"Train acc\" : self.train_acc_tracker.result()\n",
        "        }\n",
        "    @tf.function\n",
        "    def test_step(self, val_inp):\n",
        "        x_val, y_val = val_inp\n",
        "        mu,sigma = self.encoder(x_val)\n",
        "        sigma = tf.math.softplus(sigma-5)\n",
        "        z_dist = ds.Normal(mu, sigma)\n",
        "        z = z_dist.sample()\n",
        "        y = self.decoder(z)\n",
        "        info_loss = tf.reduce_sum(tf.reduce_mean(ds.kl_divergence(z_dist, prior), 0)) /math.log(2)\n",
        "        class_loss = tf.compat.v1.losses.softmax_cross_entropy(logits=y, onehot_labels=y_val)\n",
        "        val_loss =  class_loss + BETA*info_loss\n",
        "        val_acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(tf.nn.softmax(y), 1), tf.argmax(y_val, axis=1)), tf.float32))\n",
        "        self.val_loss_tracker.update_state(val_loss)\n",
        "        self.val_acc_tracker.update_state(val_acc)\n",
        "        return {\n",
        "            \"acc\" : self.val_acc_tracker.result(),\n",
        "            \"loss\" : self.val_loss_tracker.result()\n",
        "        }\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-ROMis14ZFo",
        "outputId": "d05a7896-a04b-4a59-bc8a-9553c0423ec8"
      },
      "source": [
        "vae = VAE()\n",
        "vae.compile(optimizer=keras.optimizers.Adam(lr=5e-4), metrics=[tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')])\n",
        "history = vae.fit(X_train,Y_train,validation_data=(X_test, Y_test), epochs=10000, batch_size=1024, callbacks=[keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/IB_checkpoints/', monitor='val_loss', verbose=0, save_best_only=True,\n",
        "                                                        mode='auto'),keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 2, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 2, 128, 1)    0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 2, 128, 5)    0           reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 2, 126, 256)  4096        zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 2, 126, 256)  0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, 2, 126, 260)  0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 1, 124, 80)   124880      zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 1, 124, 80)   0           conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 9920)         0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "mu (Dense)                      (None, 512)          5079552     flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_4 (Sli (None, 256)          0           mu[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_5 (Sli (None, 256)          0           mu[0][0]                         \n",
            "==================================================================================================\n",
            "Total params: 5,208,528\n",
            "Trainable params: 5,208,528\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 256)]             0         \n",
            "_________________________________________________________________\n",
            "dense3 (Dense)               (None, 11)                2827      \n",
            "=================================================================\n",
            "Total params: 2,827\n",
            "Trainable params: 2,827\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "108/108 [==============================] - 9s 61ms/step - loss: 4.0600 - info_loss: 413.0137 - class_loss: 2.4518 - IZY_bound: 0.8702 - IZX_bound: 413.0137 - Train acc: 0.0954 - val_acc: 0.0909 - val_loss: 2.8020\n",
            "Epoch 2/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 2.7904 - info_loss: 182.4389 - class_loss: 2.4180 - IZY_bound: 0.9039 - IZX_bound: 182.4389 - Train acc: 0.0921 - val_acc: 0.0921 - val_loss: 2.7849\n",
            "Epoch 3/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 2.7656 - info_loss: 176.0393 - class_loss: 2.4100 - IZY_bound: 0.9120 - IZX_bound: 176.0393 - Train acc: 0.0908 - val_acc: 0.0919 - val_loss: 2.7750\n",
            "Epoch 4/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 2.7534 - info_loss: 172.5112 - class_loss: 2.4061 - IZY_bound: 0.9158 - IZX_bound: 172.5112 - Train acc: 0.0885 - val_acc: 0.0917 - val_loss: 2.7682\n",
            "Epoch 5/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 2.7477 - info_loss: 170.1490 - class_loss: 2.4042 - IZY_bound: 0.9177 - IZX_bound: 170.1490 - Train acc: 0.0907 - val_acc: 0.0916 - val_loss: 2.7605\n",
            "Epoch 6/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 2.7289 - info_loss: 161.6295 - class_loss: 2.4031 - IZY_bound: 0.9188 - IZX_bound: 161.6295 - Train acc: 0.0916 - val_acc: 0.0921 - val_loss: 2.7526\n",
            "Epoch 7/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 2.7129 - info_loss: 155.1067 - class_loss: 2.4020 - IZY_bound: 0.9200 - IZX_bound: 155.1067 - Train acc: 0.0914 - val_acc: 0.0924 - val_loss: 2.7466\n",
            "Epoch 8/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 2.7091 - info_loss: 151.7800 - class_loss: 2.3994 - IZY_bound: 0.9225 - IZX_bound: 151.7800 - Train acc: 0.0925 - val_acc: 0.0956 - val_loss: 2.7385\n",
            "Epoch 9/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 2.6702 - info_loss: 139.9555 - class_loss: 2.3632 - IZY_bound: 0.9588 - IZX_bound: 139.9555 - Train acc: 0.1191 - val_acc: 0.1036 - val_loss: 2.7170\n",
            "Epoch 10/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 2.5351 - info_loss: 103.4652 - class_loss: 2.2879 - IZY_bound: 1.0340 - IZX_bound: 103.4652 - Train acc: 0.1499 - val_acc: 0.1111 - val_loss: 2.6804\n",
            "Epoch 11/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 2.4071 - info_loss: 66.7954 - class_loss: 2.2619 - IZY_bound: 1.0601 - IZX_bound: 66.7954 - Train acc: 0.1522 - val_acc: 0.1177 - val_loss: 2.6459\n",
            "Epoch 12/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 2.3663 - info_loss: 53.9064 - class_loss: 2.2515 - IZY_bound: 1.0704 - IZX_bound: 53.9064 - Train acc: 0.1567 - val_acc: 0.1233 - val_loss: 2.6149\n",
            "Epoch 13/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 2.3427 - info_loss: 44.4514 - class_loss: 2.2471 - IZY_bound: 1.0749 - IZX_bound: 44.4514 - Train acc: 0.1585 - val_acc: 0.1284 - val_loss: 2.5868\n",
            "Epoch 14/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 2.3290 - info_loss: 41.9764 - class_loss: 2.2428 - IZY_bound: 1.0792 - IZX_bound: 41.9764 - Train acc: 0.1583 - val_acc: 0.1324 - val_loss: 2.5625\n",
            "Epoch 15/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 2.3227 - info_loss: 41.4356 - class_loss: 2.2407 - IZY_bound: 1.0813 - IZX_bound: 41.4356 - Train acc: 0.1598 - val_acc: 0.1363 - val_loss: 2.5406\n",
            "Epoch 16/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 2.3072 - info_loss: 30.1474 - class_loss: 2.2394 - IZY_bound: 1.0825 - IZX_bound: 30.1474 - Train acc: 0.1602 - val_acc: 0.1400 - val_loss: 2.5201\n",
            "Epoch 17/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 2.2971 - info_loss: 28.2636 - class_loss: 2.2387 - IZY_bound: 1.0832 - IZX_bound: 28.2636 - Train acc: 0.1624 - val_acc: 0.1431 - val_loss: 2.5019\n",
            "Epoch 18/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 2.2902 - info_loss: 25.1649 - class_loss: 2.2365 - IZY_bound: 1.0854 - IZX_bound: 25.1649 - Train acc: 0.1658 - val_acc: 0.1463 - val_loss: 2.4847\n",
            "Epoch 19/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 2.2784 - info_loss: 19.4364 - class_loss: 2.2341 - IZY_bound: 1.0878 - IZX_bound: 19.4364 - Train acc: 0.1663 - val_acc: 0.1493 - val_loss: 2.4685\n",
            "Epoch 20/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 2.2620 - info_loss: 14.6831 - class_loss: 2.2319 - IZY_bound: 1.0901 - IZX_bound: 14.6831 - Train acc: 0.1702 - val_acc: 0.1525 - val_loss: 2.4535\n",
            "Epoch 21/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 2.2606 - info_loss: 15.3145 - class_loss: 2.2285 - IZY_bound: 1.0934 - IZX_bound: 15.3145 - Train acc: 0.1751 - val_acc: 0.1556 - val_loss: 2.4395\n",
            "Epoch 22/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 2.2517 - info_loss: 11.7394 - class_loss: 2.2196 - IZY_bound: 1.1023 - IZX_bound: 11.7394 - Train acc: 0.1790 - val_acc: 0.1591 - val_loss: 2.4252\n",
            "Epoch 23/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 2.2293 - info_loss: 10.1060 - class_loss: 2.2059 - IZY_bound: 1.1160 - IZX_bound: 10.1060 - Train acc: 0.1898 - val_acc: 0.1634 - val_loss: 2.4110\n",
            "Epoch 24/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 2.2135 - info_loss: 11.6124 - class_loss: 2.1868 - IZY_bound: 1.1352 - IZX_bound: 11.6124 - Train acc: 0.2084 - val_acc: 0.1683 - val_loss: 2.3968\n",
            "Epoch 25/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 2.1953 - info_loss: 14.2279 - class_loss: 2.1593 - IZY_bound: 1.1626 - IZX_bound: 14.2279 - Train acc: 0.2213 - val_acc: 0.1744 - val_loss: 2.3808\n",
            "Epoch 26/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 2.1509 - info_loss: 22.5293 - class_loss: 2.0831 - IZY_bound: 1.2388 - IZX_bound: 22.5293 - Train acc: 0.2477 - val_acc: 0.1812 - val_loss: 2.3611\n",
            "Epoch 27/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 2.0639 - info_loss: 29.7063 - class_loss: 1.9837 - IZY_bound: 1.3383 - IZX_bound: 29.7063 - Train acc: 0.2730 - val_acc: 0.1890 - val_loss: 2.3373\n",
            "Epoch 28/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.9837 - info_loss: 34.5688 - class_loss: 1.9022 - IZY_bound: 1.4197 - IZX_bound: 34.5688 - Train acc: 0.2956 - val_acc: 0.1967 - val_loss: 2.3130\n",
            "Epoch 29/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.9309 - info_loss: 39.2903 - class_loss: 1.8408 - IZY_bound: 1.4811 - IZX_bound: 39.2903 - Train acc: 0.3096 - val_acc: 0.2053 - val_loss: 2.2870\n",
            "Epoch 30/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.8854 - info_loss: 41.5555 - class_loss: 1.7953 - IZY_bound: 1.5267 - IZX_bound: 41.5555 - Train acc: 0.3251 - val_acc: 0.2139 - val_loss: 2.2603\n",
            "Epoch 31/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.8550 - info_loss: 42.5335 - class_loss: 1.7626 - IZY_bound: 1.5593 - IZX_bound: 42.5335 - Train acc: 0.3371 - val_acc: 0.2223 - val_loss: 2.2348\n",
            "Epoch 32/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.8308 - info_loss: 42.4715 - class_loss: 1.7417 - IZY_bound: 1.5802 - IZX_bound: 42.4715 - Train acc: 0.3446 - val_acc: 0.2302 - val_loss: 2.2099\n",
            "Epoch 33/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.8139 - info_loss: 42.5332 - class_loss: 1.7237 - IZY_bound: 1.5983 - IZX_bound: 42.5332 - Train acc: 0.3479 - val_acc: 0.2377 - val_loss: 2.1861\n",
            "Epoch 34/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.7963 - info_loss: 42.7253 - class_loss: 1.7072 - IZY_bound: 1.6148 - IZX_bound: 42.7253 - Train acc: 0.3536 - val_acc: 0.2454 - val_loss: 2.1623\n",
            "Epoch 35/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.7828 - info_loss: 42.0856 - class_loss: 1.6929 - IZY_bound: 1.6290 - IZX_bound: 42.0856 - Train acc: 0.3607 - val_acc: 0.2529 - val_loss: 2.1391\n",
            "Epoch 36/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.7712 - info_loss: 42.8755 - class_loss: 1.6789 - IZY_bound: 1.6430 - IZX_bound: 42.8755 - Train acc: 0.3650 - val_acc: 0.2601 - val_loss: 2.1168\n",
            "Epoch 37/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.7556 - info_loss: 42.9581 - class_loss: 1.6655 - IZY_bound: 1.6564 - IZX_bound: 42.9581 - Train acc: 0.3749 - val_acc: 0.2674 - val_loss: 2.0950\n",
            "Epoch 38/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.7367 - info_loss: 43.1545 - class_loss: 1.6390 - IZY_bound: 1.6830 - IZX_bound: 43.1545 - Train acc: 0.3847 - val_acc: 0.2754 - val_loss: 2.0728\n",
            "Epoch 39/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.6909 - info_loss: 44.4659 - class_loss: 1.6011 - IZY_bound: 1.7208 - IZX_bound: 44.4659 - Train acc: 0.4105 - val_acc: 0.2836 - val_loss: 2.0500\n",
            "Epoch 40/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.6652 - info_loss: 45.9694 - class_loss: 1.5633 - IZY_bound: 1.7587 - IZX_bound: 45.9694 - Train acc: 0.4226 - val_acc: 0.2921 - val_loss: 2.0265\n",
            "Epoch 41/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.6417 - info_loss: 47.2831 - class_loss: 1.5360 - IZY_bound: 1.7859 - IZX_bound: 47.2831 - Train acc: 0.4335 - val_acc: 0.3008 - val_loss: 2.0031\n",
            "Epoch 42/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.6098 - info_loss: 48.0326 - class_loss: 1.5113 - IZY_bound: 1.8107 - IZX_bound: 48.0326 - Train acc: 0.4449 - val_acc: 0.3091 - val_loss: 1.9804\n",
            "Epoch 43/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.5949 - info_loss: 48.8190 - class_loss: 1.4989 - IZY_bound: 1.8231 - IZX_bound: 48.8190 - Train acc: 0.4455 - val_acc: 0.3170 - val_loss: 1.9586\n",
            "Epoch 44/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.5843 - info_loss: 49.0122 - class_loss: 1.4878 - IZY_bound: 1.8342 - IZX_bound: 49.0122 - Train acc: 0.4484 - val_acc: 0.3246 - val_loss: 1.9372\n",
            "Epoch 45/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.5781 - info_loss: 49.3124 - class_loss: 1.4789 - IZY_bound: 1.8431 - IZX_bound: 49.3124 - Train acc: 0.4506 - val_acc: 0.3320 - val_loss: 1.9164\n",
            "Epoch 46/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.5713 - info_loss: 49.3636 - class_loss: 1.4710 - IZY_bound: 1.8509 - IZX_bound: 49.3636 - Train acc: 0.4516 - val_acc: 0.3392 - val_loss: 1.8960\n",
            "Epoch 47/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.5666 - info_loss: 49.7113 - class_loss: 1.4657 - IZY_bound: 1.8563 - IZX_bound: 49.7113 - Train acc: 0.4544 - val_acc: 0.3459 - val_loss: 1.8763\n",
            "Epoch 48/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.5617 - info_loss: 49.5204 - class_loss: 1.4613 - IZY_bound: 1.8606 - IZX_bound: 49.5204 - Train acc: 0.4524 - val_acc: 0.3526 - val_loss: 1.8571\n",
            "Epoch 49/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.5516 - info_loss: 49.2441 - class_loss: 1.4532 - IZY_bound: 1.8688 - IZX_bound: 49.2441 - Train acc: 0.4564 - val_acc: 0.3588 - val_loss: 1.8391\n",
            "Epoch 50/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.5500 - info_loss: 49.5294 - class_loss: 1.4521 - IZY_bound: 1.8698 - IZX_bound: 49.5294 - Train acc: 0.4548 - val_acc: 0.3649 - val_loss: 1.8214\n",
            "Epoch 51/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.5432 - info_loss: 49.0219 - class_loss: 1.4440 - IZY_bound: 1.8779 - IZX_bound: 49.0219 - Train acc: 0.4580 - val_acc: 0.3709 - val_loss: 1.8041\n",
            "Epoch 52/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.5367 - info_loss: 48.9633 - class_loss: 1.4396 - IZY_bound: 1.8823 - IZX_bound: 48.9633 - Train acc: 0.4610 - val_acc: 0.3767 - val_loss: 1.7872\n",
            "Epoch 53/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.5297 - info_loss: 48.6498 - class_loss: 1.4364 - IZY_bound: 1.8855 - IZX_bound: 48.6498 - Train acc: 0.4603 - val_acc: 0.3822 - val_loss: 1.7710\n",
            "Epoch 54/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.5298 - info_loss: 48.6204 - class_loss: 1.4344 - IZY_bound: 1.8875 - IZX_bound: 48.6204 - Train acc: 0.4611 - val_acc: 0.3874 - val_loss: 1.7556\n",
            "Epoch 55/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.5284 - info_loss: 48.5452 - class_loss: 1.4308 - IZY_bound: 1.8912 - IZX_bound: 48.5452 - Train acc: 0.4602 - val_acc: 0.3926 - val_loss: 1.7402\n",
            "Epoch 56/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.5275 - info_loss: 48.1734 - class_loss: 1.4286 - IZY_bound: 1.8933 - IZX_bound: 48.1734 - Train acc: 0.4616 - val_acc: 0.3975 - val_loss: 1.7256\n",
            "Epoch 57/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.5224 - info_loss: 47.8381 - class_loss: 1.4250 - IZY_bound: 1.8969 - IZX_bound: 47.8381 - Train acc: 0.4615 - val_acc: 0.4023 - val_loss: 1.7114\n",
            "Epoch 58/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.5199 - info_loss: 47.8364 - class_loss: 1.4229 - IZY_bound: 1.8990 - IZX_bound: 47.8364 - Train acc: 0.4631 - val_acc: 0.4067 - val_loss: 1.6985\n",
            "Epoch 59/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.5169 - info_loss: 47.5425 - class_loss: 1.4211 - IZY_bound: 1.9008 - IZX_bound: 47.5425 - Train acc: 0.4656 - val_acc: 0.4112 - val_loss: 1.6851\n",
            "Epoch 60/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.5157 - info_loss: 47.6093 - class_loss: 1.4173 - IZY_bound: 1.9047 - IZX_bound: 47.6093 - Train acc: 0.4642 - val_acc: 0.4154 - val_loss: 1.6722\n",
            "Epoch 61/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.5117 - info_loss: 47.3391 - class_loss: 1.4177 - IZY_bound: 1.9042 - IZX_bound: 47.3391 - Train acc: 0.4641 - val_acc: 0.4196 - val_loss: 1.6594\n",
            "Epoch 62/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.5109 - info_loss: 46.8825 - class_loss: 1.4148 - IZY_bound: 1.9071 - IZX_bound: 46.8825 - Train acc: 0.4652 - val_acc: 0.4238 - val_loss: 1.6469\n",
            "Epoch 63/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.5084 - info_loss: 47.3602 - class_loss: 1.4113 - IZY_bound: 1.9106 - IZX_bound: 47.3602 - Train acc: 0.4652 - val_acc: 0.4279 - val_loss: 1.6347\n",
            "Epoch 64/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.5005 - info_loss: 47.2423 - class_loss: 1.4095 - IZY_bound: 1.9124 - IZX_bound: 47.2423 - Train acc: 0.4675 - val_acc: 0.4317 - val_loss: 1.6232\n",
            "Epoch 65/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.5019 - info_loss: 46.7987 - class_loss: 1.4069 - IZY_bound: 1.9150 - IZX_bound: 46.7987 - Train acc: 0.4660 - val_acc: 0.4354 - val_loss: 1.6120\n",
            "Epoch 66/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4995 - info_loss: 46.9211 - class_loss: 1.4039 - IZY_bound: 1.9181 - IZX_bound: 46.9211 - Train acc: 0.4699 - val_acc: 0.4390 - val_loss: 1.6010\n",
            "Epoch 67/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4942 - info_loss: 46.6927 - class_loss: 1.4033 - IZY_bound: 1.9186 - IZX_bound: 46.6927 - Train acc: 0.4716 - val_acc: 0.4426 - val_loss: 1.5902\n",
            "Epoch 68/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4923 - info_loss: 46.4311 - class_loss: 1.4003 - IZY_bound: 1.9216 - IZX_bound: 46.4311 - Train acc: 0.4713 - val_acc: 0.4461 - val_loss: 1.5796\n",
            "Epoch 69/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4934 - info_loss: 46.1987 - class_loss: 1.3976 - IZY_bound: 1.9244 - IZX_bound: 46.1987 - Train acc: 0.4685 - val_acc: 0.4495 - val_loss: 1.5693\n",
            "Epoch 70/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4875 - info_loss: 46.3816 - class_loss: 1.3972 - IZY_bound: 1.9247 - IZX_bound: 46.3816 - Train acc: 0.4717 - val_acc: 0.4528 - val_loss: 1.5593\n",
            "Epoch 71/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.4849 - info_loss: 46.4441 - class_loss: 1.3947 - IZY_bound: 1.9272 - IZX_bound: 46.4441 - Train acc: 0.4725 - val_acc: 0.4560 - val_loss: 1.5495\n",
            "Epoch 72/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4849 - info_loss: 46.0507 - class_loss: 1.3929 - IZY_bound: 1.9290 - IZX_bound: 46.0507 - Train acc: 0.4710 - val_acc: 0.4591 - val_loss: 1.5399\n",
            "Epoch 73/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.4824 - info_loss: 46.0512 - class_loss: 1.3917 - IZY_bound: 1.9302 - IZX_bound: 46.0512 - Train acc: 0.4746 - val_acc: 0.4623 - val_loss: 1.5304\n",
            "Epoch 74/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4753 - info_loss: 45.8688 - class_loss: 1.3883 - IZY_bound: 1.9337 - IZX_bound: 45.8688 - Train acc: 0.4750 - val_acc: 0.4652 - val_loss: 1.5213\n",
            "Epoch 75/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4792 - info_loss: 46.1352 - class_loss: 1.3900 - IZY_bound: 1.9319 - IZX_bound: 46.1352 - Train acc: 0.4710 - val_acc: 0.4681 - val_loss: 1.5124\n",
            "Epoch 76/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4808 - info_loss: 45.5614 - class_loss: 1.3848 - IZY_bound: 1.9371 - IZX_bound: 45.5614 - Train acc: 0.4713 - val_acc: 0.4709 - val_loss: 1.5038\n",
            "Epoch 77/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.4778 - info_loss: 45.9586 - class_loss: 1.3840 - IZY_bound: 1.9380 - IZX_bound: 45.9586 - Train acc: 0.4768 - val_acc: 0.4736 - val_loss: 1.4953\n",
            "Epoch 78/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.4718 - info_loss: 45.3165 - class_loss: 1.3801 - IZY_bound: 1.9418 - IZX_bound: 45.3165 - Train acc: 0.4752 - val_acc: 0.4763 - val_loss: 1.4870\n",
            "Epoch 79/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4728 - info_loss: 45.5752 - class_loss: 1.3799 - IZY_bound: 1.9420 - IZX_bound: 45.5752 - Train acc: 0.4738 - val_acc: 0.4789 - val_loss: 1.4789\n",
            "Epoch 80/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4715 - info_loss: 45.7295 - class_loss: 1.3802 - IZY_bound: 1.9418 - IZX_bound: 45.7295 - Train acc: 0.4761 - val_acc: 0.4813 - val_loss: 1.4711\n",
            "Epoch 81/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4664 - info_loss: 45.1325 - class_loss: 1.3765 - IZY_bound: 1.9454 - IZX_bound: 45.1325 - Train acc: 0.4786 - val_acc: 0.4838 - val_loss: 1.4633\n",
            "Epoch 82/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4644 - info_loss: 45.1577 - class_loss: 1.3733 - IZY_bound: 1.9486 - IZX_bound: 45.1577 - Train acc: 0.4765 - val_acc: 0.4862 - val_loss: 1.4557\n",
            "Epoch 83/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4661 - info_loss: 45.1916 - class_loss: 1.3733 - IZY_bound: 1.9486 - IZX_bound: 45.1916 - Train acc: 0.4773 - val_acc: 0.4886 - val_loss: 1.4483\n",
            "Epoch 84/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4587 - info_loss: 44.8430 - class_loss: 1.3710 - IZY_bound: 1.9509 - IZX_bound: 44.8430 - Train acc: 0.4773 - val_acc: 0.4909 - val_loss: 1.4411\n",
            "Epoch 85/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.4570 - info_loss: 44.6945 - class_loss: 1.3690 - IZY_bound: 1.9529 - IZX_bound: 44.6945 - Train acc: 0.4796 - val_acc: 0.4932 - val_loss: 1.4338\n",
            "Epoch 86/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4505 - info_loss: 44.8377 - class_loss: 1.3661 - IZY_bound: 1.9559 - IZX_bound: 44.8377 - Train acc: 0.4840 - val_acc: 0.4955 - val_loss: 1.4268\n",
            "Epoch 87/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4585 - info_loss: 44.6447 - class_loss: 1.3647 - IZY_bound: 1.9572 - IZX_bound: 44.6447 - Train acc: 0.4793 - val_acc: 0.4976 - val_loss: 1.4201\n",
            "Epoch 88/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4546 - info_loss: 44.4858 - class_loss: 1.3642 - IZY_bound: 1.9577 - IZX_bound: 44.4858 - Train acc: 0.4815 - val_acc: 0.4998 - val_loss: 1.4133\n",
            "Epoch 89/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4510 - info_loss: 44.6387 - class_loss: 1.3604 - IZY_bound: 1.9615 - IZX_bound: 44.6387 - Train acc: 0.4824 - val_acc: 0.5020 - val_loss: 1.4066\n",
            "Epoch 90/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4474 - info_loss: 44.3828 - class_loss: 1.3597 - IZY_bound: 1.9622 - IZX_bound: 44.3828 - Train acc: 0.4845 - val_acc: 0.5041 - val_loss: 1.4000\n",
            "Epoch 91/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4429 - info_loss: 44.1906 - class_loss: 1.3564 - IZY_bound: 1.9655 - IZX_bound: 44.1906 - Train acc: 0.4892 - val_acc: 0.5062 - val_loss: 1.3935\n",
            "Epoch 92/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.4481 - info_loss: 44.6312 - class_loss: 1.3586 - IZY_bound: 1.9633 - IZX_bound: 44.6312 - Train acc: 0.4841 - val_acc: 0.5082 - val_loss: 1.3874\n",
            "Epoch 93/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4444 - info_loss: 44.3755 - class_loss: 1.3523 - IZY_bound: 1.9696 - IZX_bound: 44.3755 - Train acc: 0.4868 - val_acc: 0.5102 - val_loss: 1.3813\n",
            "Epoch 94/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4414 - info_loss: 44.4160 - class_loss: 1.3515 - IZY_bound: 1.9705 - IZX_bound: 44.4160 - Train acc: 0.4867 - val_acc: 0.5122 - val_loss: 1.3751\n",
            "Epoch 95/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.4357 - info_loss: 43.9879 - class_loss: 1.3477 - IZY_bound: 1.9742 - IZX_bound: 43.9879 - Train acc: 0.4900 - val_acc: 0.5142 - val_loss: 1.3693\n",
            "Epoch 96/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.4353 - info_loss: 43.8786 - class_loss: 1.3479 - IZY_bound: 1.9740 - IZX_bound: 43.8786 - Train acc: 0.4906 - val_acc: 0.5160 - val_loss: 1.3635\n",
            "Epoch 97/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4338 - info_loss: 44.1049 - class_loss: 1.3455 - IZY_bound: 1.9764 - IZX_bound: 44.1049 - Train acc: 0.4916 - val_acc: 0.5179 - val_loss: 1.3579\n",
            "Epoch 98/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4284 - info_loss: 44.1040 - class_loss: 1.3408 - IZY_bound: 1.9812 - IZX_bound: 44.1040 - Train acc: 0.4954 - val_acc: 0.5198 - val_loss: 1.3522\n",
            "Epoch 99/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.4284 - info_loss: 44.2742 - class_loss: 1.3390 - IZY_bound: 1.9829 - IZX_bound: 44.2742 - Train acc: 0.4990 - val_acc: 0.5217 - val_loss: 1.3467\n",
            "Epoch 100/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4235 - info_loss: 44.0583 - class_loss: 1.3343 - IZY_bound: 1.9876 - IZX_bound: 44.0583 - Train acc: 0.4998 - val_acc: 0.5237 - val_loss: 1.3411\n",
            "Epoch 101/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4161 - info_loss: 43.8404 - class_loss: 1.3291 - IZY_bound: 1.9928 - IZX_bound: 43.8404 - Train acc: 0.5024 - val_acc: 0.5256 - val_loss: 1.3354\n",
            "Epoch 102/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4203 - info_loss: 44.1919 - class_loss: 1.3266 - IZY_bound: 1.9953 - IZX_bound: 44.1919 - Train acc: 0.5023 - val_acc: 0.5276 - val_loss: 1.3299\n",
            "Epoch 103/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4148 - info_loss: 44.0321 - class_loss: 1.3242 - IZY_bound: 1.9978 - IZX_bound: 44.0321 - Train acc: 0.5056 - val_acc: 0.5295 - val_loss: 1.3244\n",
            "Epoch 104/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4065 - info_loss: 43.9873 - class_loss: 1.3190 - IZY_bound: 2.0030 - IZX_bound: 43.9873 - Train acc: 0.5083 - val_acc: 0.5315 - val_loss: 1.3189\n",
            "Epoch 105/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.4030 - info_loss: 44.2693 - class_loss: 1.3162 - IZY_bound: 2.0058 - IZX_bound: 44.2693 - Train acc: 0.5099 - val_acc: 0.5334 - val_loss: 1.3136\n",
            "Epoch 106/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.4023 - info_loss: 43.8732 - class_loss: 1.3121 - IZY_bound: 2.0099 - IZX_bound: 43.8732 - Train acc: 0.5135 - val_acc: 0.5353 - val_loss: 1.3083\n",
            "Epoch 107/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.4002 - info_loss: 43.9958 - class_loss: 1.3105 - IZY_bound: 2.0114 - IZX_bound: 43.9958 - Train acc: 0.5116 - val_acc: 0.5370 - val_loss: 1.3031\n",
            "Epoch 108/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.3974 - info_loss: 43.5885 - class_loss: 1.3064 - IZY_bound: 2.0155 - IZX_bound: 43.5885 - Train acc: 0.5135 - val_acc: 0.5388 - val_loss: 1.2981\n",
            "Epoch 109/10000\n",
            "108/108 [==============================] - 6s 52ms/step - loss: 1.3923 - info_loss: 43.6845 - class_loss: 1.3047 - IZY_bound: 2.0172 - IZX_bound: 43.6845 - Train acc: 0.5155 - val_acc: 0.5406 - val_loss: 1.2930\n",
            "Epoch 110/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3923 - info_loss: 43.4138 - class_loss: 1.3014 - IZY_bound: 2.0205 - IZX_bound: 43.4138 - Train acc: 0.5148 - val_acc: 0.5424 - val_loss: 1.2878\n",
            "Epoch 111/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3859 - info_loss: 43.7440 - class_loss: 1.3004 - IZY_bound: 2.0216 - IZX_bound: 43.7440 - Train acc: 0.5166 - val_acc: 0.5441 - val_loss: 1.2830\n",
            "Epoch 112/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3820 - info_loss: 43.4405 - class_loss: 1.2985 - IZY_bound: 2.0234 - IZX_bound: 43.4405 - Train acc: 0.5176 - val_acc: 0.5458 - val_loss: 1.2782\n",
            "Epoch 113/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3830 - info_loss: 43.4081 - class_loss: 1.2952 - IZY_bound: 2.0267 - IZX_bound: 43.4081 - Train acc: 0.5169 - val_acc: 0.5475 - val_loss: 1.2733\n",
            "Epoch 114/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3760 - info_loss: 43.2897 - class_loss: 1.2940 - IZY_bound: 2.0279 - IZX_bound: 43.2897 - Train acc: 0.5206 - val_acc: 0.5491 - val_loss: 1.2686\n",
            "Epoch 115/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3802 - info_loss: 43.2920 - class_loss: 1.2946 - IZY_bound: 2.0273 - IZX_bound: 43.2920 - Train acc: 0.5214 - val_acc: 0.5508 - val_loss: 1.2638\n",
            "Epoch 116/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3833 - info_loss: 43.2940 - class_loss: 1.2912 - IZY_bound: 2.0307 - IZX_bound: 43.2940 - Train acc: 0.5175 - val_acc: 0.5524 - val_loss: 1.2592\n",
            "Epoch 117/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3703 - info_loss: 43.0741 - class_loss: 1.2852 - IZY_bound: 2.0368 - IZX_bound: 43.0741 - Train acc: 0.5213 - val_acc: 0.5540 - val_loss: 1.2546\n",
            "Epoch 118/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3734 - info_loss: 43.1866 - class_loss: 1.2857 - IZY_bound: 2.0363 - IZX_bound: 43.1866 - Train acc: 0.5207 - val_acc: 0.5556 - val_loss: 1.2500\n",
            "Epoch 119/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3674 - info_loss: 43.0851 - class_loss: 1.2836 - IZY_bound: 2.0383 - IZX_bound: 43.0851 - Train acc: 0.5235 - val_acc: 0.5572 - val_loss: 1.2455\n",
            "Epoch 120/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.3708 - info_loss: 43.0259 - class_loss: 1.2820 - IZY_bound: 2.0399 - IZX_bound: 43.0259 - Train acc: 0.5231 - val_acc: 0.5587 - val_loss: 1.2410\n",
            "Epoch 121/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.3578 - info_loss: 43.0275 - class_loss: 1.2761 - IZY_bound: 2.0459 - IZX_bound: 43.0275 - Train acc: 0.5267 - val_acc: 0.5602 - val_loss: 1.2369\n",
            "Epoch 122/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.3594 - info_loss: 42.9473 - class_loss: 1.2757 - IZY_bound: 2.0462 - IZX_bound: 42.9473 - Train acc: 0.5266 - val_acc: 0.5616 - val_loss: 1.2326\n",
            "Epoch 123/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.3703 - info_loss: 43.1477 - class_loss: 1.2781 - IZY_bound: 2.0439 - IZX_bound: 43.1477 - Train acc: 0.5230 - val_acc: 0.5631 - val_loss: 1.2283\n",
            "Epoch 124/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3626 - info_loss: 43.0964 - class_loss: 1.2736 - IZY_bound: 2.0483 - IZX_bound: 43.0964 - Train acc: 0.5239 - val_acc: 0.5645 - val_loss: 1.2243\n",
            "Epoch 125/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3601 - info_loss: 42.9976 - class_loss: 1.2683 - IZY_bound: 2.0536 - IZX_bound: 42.9976 - Train acc: 0.5245 - val_acc: 0.5659 - val_loss: 1.2202\n",
            "Epoch 126/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3553 - info_loss: 42.8275 - class_loss: 1.2681 - IZY_bound: 2.0538 - IZX_bound: 42.8275 - Train acc: 0.5293 - val_acc: 0.5674 - val_loss: 1.2160\n",
            "Epoch 127/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3505 - info_loss: 42.9716 - class_loss: 1.2664 - IZY_bound: 2.0556 - IZX_bound: 42.9716 - Train acc: 0.5296 - val_acc: 0.5688 - val_loss: 1.2121\n",
            "Epoch 128/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3513 - info_loss: 43.0473 - class_loss: 1.2645 - IZY_bound: 2.0574 - IZX_bound: 43.0473 - Train acc: 0.5301 - val_acc: 0.5702 - val_loss: 1.2080\n",
            "Epoch 129/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3460 - info_loss: 43.2194 - class_loss: 1.2620 - IZY_bound: 2.0599 - IZX_bound: 43.2194 - Train acc: 0.5325 - val_acc: 0.5716 - val_loss: 1.2040\n",
            "Epoch 130/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.3503 - info_loss: 42.8624 - class_loss: 1.2591 - IZY_bound: 2.0628 - IZX_bound: 42.8624 - Train acc: 0.5303 - val_acc: 0.5730 - val_loss: 1.2000\n",
            "Epoch 131/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3403 - info_loss: 43.1645 - class_loss: 1.2577 - IZY_bound: 2.0642 - IZX_bound: 43.1645 - Train acc: 0.5370 - val_acc: 0.5743 - val_loss: 1.1963\n",
            "Epoch 132/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3377 - info_loss: 42.9027 - class_loss: 1.2535 - IZY_bound: 2.0685 - IZX_bound: 42.9027 - Train acc: 0.5382 - val_acc: 0.5757 - val_loss: 1.1925\n",
            "Epoch 133/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3398 - info_loss: 42.9811 - class_loss: 1.2532 - IZY_bound: 2.0688 - IZX_bound: 42.9811 - Train acc: 0.5352 - val_acc: 0.5771 - val_loss: 1.1887\n",
            "Epoch 134/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3383 - info_loss: 42.9969 - class_loss: 1.2542 - IZY_bound: 2.0677 - IZX_bound: 42.9969 - Train acc: 0.5366 - val_acc: 0.5784 - val_loss: 1.1850\n",
            "Epoch 135/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3394 - info_loss: 43.1129 - class_loss: 1.2507 - IZY_bound: 2.0712 - IZX_bound: 43.1129 - Train acc: 0.5354 - val_acc: 0.5796 - val_loss: 1.1814\n",
            "Epoch 136/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3340 - info_loss: 42.9662 - class_loss: 1.2485 - IZY_bound: 2.0734 - IZX_bound: 42.9662 - Train acc: 0.5384 - val_acc: 0.5809 - val_loss: 1.1777\n",
            "Epoch 137/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3323 - info_loss: 43.0987 - class_loss: 1.2444 - IZY_bound: 2.0775 - IZX_bound: 43.0987 - Train acc: 0.5417 - val_acc: 0.5823 - val_loss: 1.1740\n",
            "Epoch 138/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3247 - info_loss: 42.9004 - class_loss: 1.2454 - IZY_bound: 2.0766 - IZX_bound: 42.9004 - Train acc: 0.5429 - val_acc: 0.5835 - val_loss: 1.1705\n",
            "Epoch 139/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3372 - info_loss: 43.0745 - class_loss: 1.2434 - IZY_bound: 2.0785 - IZX_bound: 43.0745 - Train acc: 0.5370 - val_acc: 0.5848 - val_loss: 1.1670\n",
            "Epoch 140/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3249 - info_loss: 43.0665 - class_loss: 1.2425 - IZY_bound: 2.0794 - IZX_bound: 43.0665 - Train acc: 0.5446 - val_acc: 0.5860 - val_loss: 1.1635\n",
            "Epoch 141/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3248 - info_loss: 42.9130 - class_loss: 1.2392 - IZY_bound: 2.0827 - IZX_bound: 42.9130 - Train acc: 0.5450 - val_acc: 0.5872 - val_loss: 1.1601\n",
            "Epoch 142/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3195 - info_loss: 43.4117 - class_loss: 1.2398 - IZY_bound: 2.0821 - IZX_bound: 43.4117 - Train acc: 0.5461 - val_acc: 0.5884 - val_loss: 1.1568\n",
            "Epoch 143/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3212 - info_loss: 43.1909 - class_loss: 1.2364 - IZY_bound: 2.0855 - IZX_bound: 43.1909 - Train acc: 0.5433 - val_acc: 0.5896 - val_loss: 1.1534\n",
            "Epoch 144/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.3242 - info_loss: 42.9753 - class_loss: 1.2355 - IZY_bound: 2.0864 - IZX_bound: 42.9753 - Train acc: 0.5421 - val_acc: 0.5908 - val_loss: 1.1501\n",
            "Epoch 145/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3137 - info_loss: 42.7873 - class_loss: 1.2306 - IZY_bound: 2.0913 - IZX_bound: 42.7873 - Train acc: 0.5496 - val_acc: 0.5920 - val_loss: 1.1469\n",
            "Epoch 146/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.3096 - info_loss: 42.9594 - class_loss: 1.2286 - IZY_bound: 2.0933 - IZX_bound: 42.9594 - Train acc: 0.5519 - val_acc: 0.5931 - val_loss: 1.1436\n",
            "Epoch 147/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3183 - info_loss: 43.0966 - class_loss: 1.2296 - IZY_bound: 2.0923 - IZX_bound: 43.0966 - Train acc: 0.5454 - val_acc: 0.5943 - val_loss: 1.1404\n",
            "Epoch 148/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3096 - info_loss: 43.0702 - class_loss: 1.2271 - IZY_bound: 2.0948 - IZX_bound: 43.0702 - Train acc: 0.5506 - val_acc: 0.5955 - val_loss: 1.1371\n",
            "Epoch 149/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3088 - info_loss: 42.8628 - class_loss: 1.2253 - IZY_bound: 2.0966 - IZX_bound: 42.8628 - Train acc: 0.5496 - val_acc: 0.5966 - val_loss: 1.1340\n",
            "Epoch 150/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.3076 - info_loss: 43.0620 - class_loss: 1.2223 - IZY_bound: 2.0997 - IZX_bound: 43.0620 - Train acc: 0.5524 - val_acc: 0.5977 - val_loss: 1.1308\n",
            "Epoch 151/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.3057 - info_loss: 43.1771 - class_loss: 1.2221 - IZY_bound: 2.0998 - IZX_bound: 43.1771 - Train acc: 0.5524 - val_acc: 0.5989 - val_loss: 1.1278\n",
            "Epoch 152/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.3031 - info_loss: 42.9443 - class_loss: 1.2202 - IZY_bound: 2.1018 - IZX_bound: 42.9443 - Train acc: 0.5511 - val_acc: 0.5999 - val_loss: 1.1247\n",
            "Epoch 153/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2978 - info_loss: 42.9482 - class_loss: 1.2168 - IZY_bound: 2.1051 - IZX_bound: 42.9482 - Train acc: 0.5552 - val_acc: 0.6010 - val_loss: 1.1218\n",
            "Epoch 154/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.3035 - info_loss: 43.4679 - class_loss: 1.2192 - IZY_bound: 2.1027 - IZX_bound: 43.4679 - Train acc: 0.5522 - val_acc: 0.6020 - val_loss: 1.1188\n",
            "Epoch 155/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2957 - info_loss: 43.0258 - class_loss: 1.2124 - IZY_bound: 2.1096 - IZX_bound: 43.0258 - Train acc: 0.5557 - val_acc: 0.6031 - val_loss: 1.1159\n",
            "Epoch 156/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2983 - info_loss: 43.2093 - class_loss: 1.2132 - IZY_bound: 2.1087 - IZX_bound: 43.2093 - Train acc: 0.5551 - val_acc: 0.6041 - val_loss: 1.1130\n",
            "Epoch 157/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2980 - info_loss: 43.4825 - class_loss: 1.2138 - IZY_bound: 2.1081 - IZX_bound: 43.4825 - Train acc: 0.5549 - val_acc: 0.6051 - val_loss: 1.1101\n",
            "Epoch 158/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2938 - info_loss: 43.0755 - class_loss: 1.2098 - IZY_bound: 2.1122 - IZX_bound: 43.0755 - Train acc: 0.5564 - val_acc: 0.6061 - val_loss: 1.1073\n",
            "Epoch 159/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2950 - info_loss: 43.3425 - class_loss: 1.2077 - IZY_bound: 2.1142 - IZX_bound: 43.3425 - Train acc: 0.5579 - val_acc: 0.6071 - val_loss: 1.1045\n",
            "Epoch 160/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2972 - info_loss: 43.2824 - class_loss: 1.2077 - IZY_bound: 2.1143 - IZX_bound: 43.2824 - Train acc: 0.5545 - val_acc: 0.6081 - val_loss: 1.1016\n",
            "Epoch 161/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2905 - info_loss: 42.9126 - class_loss: 1.2044 - IZY_bound: 2.1175 - IZX_bound: 42.9126 - Train acc: 0.5573 - val_acc: 0.6091 - val_loss: 1.0989\n",
            "Epoch 162/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2903 - info_loss: 43.0964 - class_loss: 1.2046 - IZY_bound: 2.1174 - IZX_bound: 43.0964 - Train acc: 0.5580 - val_acc: 0.6101 - val_loss: 1.0961\n",
            "Epoch 163/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2838 - info_loss: 42.7029 - class_loss: 1.1988 - IZY_bound: 2.1231 - IZX_bound: 42.7029 - Train acc: 0.5619 - val_acc: 0.6110 - val_loss: 1.0935\n",
            "Epoch 164/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2800 - info_loss: 43.3223 - class_loss: 1.1980 - IZY_bound: 2.1240 - IZX_bound: 43.3223 - Train acc: 0.5607 - val_acc: 0.6120 - val_loss: 1.0908\n",
            "Epoch 165/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2776 - info_loss: 43.1505 - class_loss: 1.1973 - IZY_bound: 2.1246 - IZX_bound: 43.1505 - Train acc: 0.5632 - val_acc: 0.6129 - val_loss: 1.0882\n",
            "Epoch 166/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2821 - info_loss: 43.2338 - class_loss: 1.1943 - IZY_bound: 2.1277 - IZX_bound: 43.2338 - Train acc: 0.5592 - val_acc: 0.6139 - val_loss: 1.0855\n",
            "Epoch 167/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2822 - info_loss: 43.2113 - class_loss: 1.1953 - IZY_bound: 2.1266 - IZX_bound: 43.2113 - Train acc: 0.5626 - val_acc: 0.6148 - val_loss: 1.0830\n",
            "Epoch 168/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2753 - info_loss: 43.5212 - class_loss: 1.1935 - IZY_bound: 2.1284 - IZX_bound: 43.5212 - Train acc: 0.5638 - val_acc: 0.6157 - val_loss: 1.0804\n",
            "Epoch 169/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2708 - info_loss: 43.2459 - class_loss: 1.1889 - IZY_bound: 2.1330 - IZX_bound: 43.2459 - Train acc: 0.5671 - val_acc: 0.6166 - val_loss: 1.0779\n",
            "Epoch 170/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2744 - info_loss: 43.3856 - class_loss: 1.1885 - IZY_bound: 2.1335 - IZX_bound: 43.3856 - Train acc: 0.5651 - val_acc: 0.6174 - val_loss: 1.0755\n",
            "Epoch 171/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2733 - info_loss: 43.5509 - class_loss: 1.1902 - IZY_bound: 2.1317 - IZX_bound: 43.5509 - Train acc: 0.5644 - val_acc: 0.6183 - val_loss: 1.0730\n",
            "Epoch 172/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2733 - info_loss: 43.3535 - class_loss: 1.1850 - IZY_bound: 2.1369 - IZX_bound: 43.3535 - Train acc: 0.5647 - val_acc: 0.6191 - val_loss: 1.0705\n",
            "Epoch 173/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2716 - info_loss: 43.4003 - class_loss: 1.1834 - IZY_bound: 2.1385 - IZX_bound: 43.4003 - Train acc: 0.5641 - val_acc: 0.6200 - val_loss: 1.0681\n",
            "Epoch 174/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2722 - info_loss: 43.3035 - class_loss: 1.1816 - IZY_bound: 2.1403 - IZX_bound: 43.3035 - Train acc: 0.5635 - val_acc: 0.6209 - val_loss: 1.0657\n",
            "Epoch 175/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2665 - info_loss: 43.4274 - class_loss: 1.1818 - IZY_bound: 2.1401 - IZX_bound: 43.4274 - Train acc: 0.5662 - val_acc: 0.6216 - val_loss: 1.0635\n",
            "Epoch 176/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2639 - info_loss: 43.4122 - class_loss: 1.1796 - IZY_bound: 2.1423 - IZX_bound: 43.4122 - Train acc: 0.5670 - val_acc: 0.6225 - val_loss: 1.0611\n",
            "Epoch 177/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2634 - info_loss: 43.3325 - class_loss: 1.1778 - IZY_bound: 2.1441 - IZX_bound: 43.3325 - Train acc: 0.5670 - val_acc: 0.6233 - val_loss: 1.0588\n",
            "Epoch 178/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2638 - info_loss: 43.3811 - class_loss: 1.1758 - IZY_bound: 2.1461 - IZX_bound: 43.3811 - Train acc: 0.5679 - val_acc: 0.6241 - val_loss: 1.0566\n",
            "Epoch 179/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2605 - info_loss: 43.7124 - class_loss: 1.1750 - IZY_bound: 2.1469 - IZX_bound: 43.7124 - Train acc: 0.5689 - val_acc: 0.6249 - val_loss: 1.0544\n",
            "Epoch 180/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2524 - info_loss: 43.4095 - class_loss: 1.1709 - IZY_bound: 2.1511 - IZX_bound: 43.4095 - Train acc: 0.5719 - val_acc: 0.6256 - val_loss: 1.0522\n",
            "Epoch 181/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2600 - info_loss: 43.6029 - class_loss: 1.1704 - IZY_bound: 2.1515 - IZX_bound: 43.6029 - Train acc: 0.5680 - val_acc: 0.6264 - val_loss: 1.0499\n",
            "Epoch 182/10000\n",
            "108/108 [==============================] - 6s 53ms/step - loss: 1.2510 - info_loss: 43.2922 - class_loss: 1.1669 - IZY_bound: 2.1550 - IZX_bound: 43.2922 - Train acc: 0.5749 - val_acc: 0.6272 - val_loss: 1.0478\n",
            "Epoch 183/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2521 - info_loss: 43.4753 - class_loss: 1.1671 - IZY_bound: 2.1548 - IZX_bound: 43.4753 - Train acc: 0.5727 - val_acc: 0.6279 - val_loss: 1.0456\n",
            "Epoch 184/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2568 - info_loss: 43.4077 - class_loss: 1.1662 - IZY_bound: 2.1557 - IZX_bound: 43.4077 - Train acc: 0.5720 - val_acc: 0.6287 - val_loss: 1.0434\n",
            "Epoch 185/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2455 - info_loss: 43.6925 - class_loss: 1.1627 - IZY_bound: 2.1593 - IZX_bound: 43.6925 - Train acc: 0.5748 - val_acc: 0.6294 - val_loss: 1.0413\n",
            "Epoch 186/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2458 - info_loss: 43.5911 - class_loss: 1.1622 - IZY_bound: 2.1598 - IZX_bound: 43.5911 - Train acc: 0.5733 - val_acc: 0.6302 - val_loss: 1.0391\n",
            "Epoch 187/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2529 - info_loss: 43.5155 - class_loss: 1.1607 - IZY_bound: 2.1612 - IZX_bound: 43.5155 - Train acc: 0.5714 - val_acc: 0.6309 - val_loss: 1.0371\n",
            "Epoch 188/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2438 - info_loss: 43.6301 - class_loss: 1.1589 - IZY_bound: 2.1631 - IZX_bound: 43.6301 - Train acc: 0.5747 - val_acc: 0.6317 - val_loss: 1.0350\n",
            "Epoch 189/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2442 - info_loss: 43.5229 - class_loss: 1.1560 - IZY_bound: 2.1660 - IZX_bound: 43.5229 - Train acc: 0.5762 - val_acc: 0.6323 - val_loss: 1.0331\n",
            "Epoch 190/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.2478 - info_loss: 43.6887 - class_loss: 1.1578 - IZY_bound: 2.1642 - IZX_bound: 43.6887 - Train acc: 0.5751 - val_acc: 0.6330 - val_loss: 1.0310\n",
            "Epoch 191/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2392 - info_loss: 43.8996 - class_loss: 1.1539 - IZY_bound: 2.1680 - IZX_bound: 43.8996 - Train acc: 0.5760 - val_acc: 0.6337 - val_loss: 1.0291\n",
            "Epoch 192/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2448 - info_loss: 43.6611 - class_loss: 1.1547 - IZY_bound: 2.1672 - IZX_bound: 43.6611 - Train acc: 0.5738 - val_acc: 0.6344 - val_loss: 1.0272\n",
            "Epoch 193/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2352 - info_loss: 43.6533 - class_loss: 1.1491 - IZY_bound: 2.1728 - IZX_bound: 43.6533 - Train acc: 0.5790 - val_acc: 0.6351 - val_loss: 1.0252\n",
            "Epoch 194/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2338 - info_loss: 43.9580 - class_loss: 1.1494 - IZY_bound: 2.1725 - IZX_bound: 43.9580 - Train acc: 0.5794 - val_acc: 0.6357 - val_loss: 1.0233\n",
            "Epoch 195/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2336 - info_loss: 43.6859 - class_loss: 1.1452 - IZY_bound: 2.1767 - IZX_bound: 43.6859 - Train acc: 0.5801 - val_acc: 0.6365 - val_loss: 1.0212\n",
            "Epoch 196/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2295 - info_loss: 43.6281 - class_loss: 1.1446 - IZY_bound: 2.1773 - IZX_bound: 43.6281 - Train acc: 0.5815 - val_acc: 0.6371 - val_loss: 1.0194\n",
            "Epoch 197/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2272 - info_loss: 43.6171 - class_loss: 1.1433 - IZY_bound: 2.1787 - IZX_bound: 43.6171 - Train acc: 0.5815 - val_acc: 0.6377 - val_loss: 1.0175\n",
            "Epoch 198/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2241 - info_loss: 43.7636 - class_loss: 1.1411 - IZY_bound: 2.1808 - IZX_bound: 43.7636 - Train acc: 0.5862 - val_acc: 0.6384 - val_loss: 1.0157\n",
            "Epoch 199/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2229 - info_loss: 43.8133 - class_loss: 1.1411 - IZY_bound: 2.1809 - IZX_bound: 43.8133 - Train acc: 0.5826 - val_acc: 0.6391 - val_loss: 1.0138\n",
            "Epoch 200/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2298 - info_loss: 44.0015 - class_loss: 1.1378 - IZY_bound: 2.1841 - IZX_bound: 44.0015 - Train acc: 0.5801 - val_acc: 0.6397 - val_loss: 1.0119\n",
            "Epoch 201/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2201 - info_loss: 43.9431 - class_loss: 1.1387 - IZY_bound: 2.1832 - IZX_bound: 43.9431 - Train acc: 0.5833 - val_acc: 0.6404 - val_loss: 1.0101\n",
            "Epoch 202/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2183 - info_loss: 43.9321 - class_loss: 1.1354 - IZY_bound: 2.1865 - IZX_bound: 43.9321 - Train acc: 0.5857 - val_acc: 0.6410 - val_loss: 1.0082\n",
            "Epoch 203/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2216 - info_loss: 43.7951 - class_loss: 1.1343 - IZY_bound: 2.1876 - IZX_bound: 43.7951 - Train acc: 0.5830 - val_acc: 0.6416 - val_loss: 1.0064\n",
            "Epoch 204/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2181 - info_loss: 44.0499 - class_loss: 1.1324 - IZY_bound: 2.1895 - IZX_bound: 44.0499 - Train acc: 0.5855 - val_acc: 0.6423 - val_loss: 1.0046\n",
            "Epoch 205/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2203 - info_loss: 44.0703 - class_loss: 1.1322 - IZY_bound: 2.1897 - IZX_bound: 44.0703 - Train acc: 0.5859 - val_acc: 0.6429 - val_loss: 1.0028\n",
            "Epoch 206/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2153 - info_loss: 44.1518 - class_loss: 1.1308 - IZY_bound: 2.1912 - IZX_bound: 44.1518 - Train acc: 0.5833 - val_acc: 0.6435 - val_loss: 1.0011\n",
            "Epoch 207/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2186 - info_loss: 44.0411 - class_loss: 1.1298 - IZY_bound: 2.1921 - IZX_bound: 44.0411 - Train acc: 0.5851 - val_acc: 0.6441 - val_loss: 0.9993\n",
            "Epoch 208/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2154 - info_loss: 44.2299 - class_loss: 1.1267 - IZY_bound: 2.1953 - IZX_bound: 44.2299 - Train acc: 0.5881 - val_acc: 0.6447 - val_loss: 0.9976\n",
            "Epoch 209/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2114 - info_loss: 43.8914 - class_loss: 1.1250 - IZY_bound: 2.1970 - IZX_bound: 43.8914 - Train acc: 0.5896 - val_acc: 0.6453 - val_loss: 0.9959\n",
            "Epoch 210/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2104 - info_loss: 43.9226 - class_loss: 1.1227 - IZY_bound: 2.1992 - IZX_bound: 43.9226 - Train acc: 0.5876 - val_acc: 0.6459 - val_loss: 0.9942\n",
            "Epoch 211/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2075 - info_loss: 44.1775 - class_loss: 1.1210 - IZY_bound: 2.2009 - IZX_bound: 44.1775 - Train acc: 0.5890 - val_acc: 0.6465 - val_loss: 0.9925\n",
            "Epoch 212/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2034 - info_loss: 43.9569 - class_loss: 1.1188 - IZY_bound: 2.2031 - IZX_bound: 43.9569 - Train acc: 0.5916 - val_acc: 0.6471 - val_loss: 0.9909\n",
            "Epoch 213/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2069 - info_loss: 44.2509 - class_loss: 1.1209 - IZY_bound: 2.2010 - IZX_bound: 44.2509 - Train acc: 0.5890 - val_acc: 0.6477 - val_loss: 0.9892\n",
            "Epoch 214/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2041 - info_loss: 44.0728 - class_loss: 1.1164 - IZY_bound: 2.2055 - IZX_bound: 44.0728 - Train acc: 0.5921 - val_acc: 0.6482 - val_loss: 0.9876\n",
            "Epoch 215/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1972 - info_loss: 44.4094 - class_loss: 1.1153 - IZY_bound: 2.2066 - IZX_bound: 44.4094 - Train acc: 0.5927 - val_acc: 0.6487 - val_loss: 0.9861\n",
            "Epoch 216/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2002 - info_loss: 44.4989 - class_loss: 1.1159 - IZY_bound: 2.2060 - IZX_bound: 44.4989 - Train acc: 0.5933 - val_acc: 0.6493 - val_loss: 0.9845\n",
            "Epoch 217/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2005 - info_loss: 44.4795 - class_loss: 1.1125 - IZY_bound: 2.2094 - IZX_bound: 44.4795 - Train acc: 0.5921 - val_acc: 0.6498 - val_loss: 0.9830\n",
            "Epoch 218/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.2004 - info_loss: 44.1616 - class_loss: 1.1103 - IZY_bound: 2.2116 - IZX_bound: 44.1616 - Train acc: 0.5920 - val_acc: 0.6504 - val_loss: 0.9815\n",
            "Epoch 219/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1997 - info_loss: 44.1901 - class_loss: 1.1081 - IZY_bound: 2.2138 - IZX_bound: 44.1901 - Train acc: 0.5916 - val_acc: 0.6509 - val_loss: 0.9800\n",
            "Epoch 220/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.2024 - info_loss: 44.2703 - class_loss: 1.1082 - IZY_bound: 2.2137 - IZX_bound: 44.2703 - Train acc: 0.5908 - val_acc: 0.6514 - val_loss: 0.9785\n",
            "Epoch 221/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1915 - info_loss: 44.5708 - class_loss: 1.1055 - IZY_bound: 2.2164 - IZX_bound: 44.5708 - Train acc: 0.5956 - val_acc: 0.6519 - val_loss: 0.9770\n",
            "Epoch 222/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1927 - info_loss: 44.2936 - class_loss: 1.1037 - IZY_bound: 2.2182 - IZX_bound: 44.2936 - Train acc: 0.5947 - val_acc: 0.6525 - val_loss: 0.9755\n",
            "Epoch 223/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1974 - info_loss: 44.5658 - class_loss: 1.1058 - IZY_bound: 2.2161 - IZX_bound: 44.5658 - Train acc: 0.5944 - val_acc: 0.6530 - val_loss: 0.9741\n",
            "Epoch 224/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1868 - info_loss: 44.6059 - class_loss: 1.1037 - IZY_bound: 2.2182 - IZX_bound: 44.6059 - Train acc: 0.5977 - val_acc: 0.6535 - val_loss: 0.9726\n",
            "Epoch 225/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1823 - info_loss: 44.5303 - class_loss: 1.0974 - IZY_bound: 2.2246 - IZX_bound: 44.5303 - Train acc: 0.5993 - val_acc: 0.6540 - val_loss: 0.9711\n",
            "Epoch 226/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1819 - info_loss: 44.4262 - class_loss: 1.0979 - IZY_bound: 2.2241 - IZX_bound: 44.4262 - Train acc: 0.6002 - val_acc: 0.6545 - val_loss: 0.9697\n",
            "Epoch 227/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1863 - info_loss: 44.7241 - class_loss: 1.0986 - IZY_bound: 2.2233 - IZX_bound: 44.7241 - Train acc: 0.5985 - val_acc: 0.6550 - val_loss: 0.9682\n",
            "Epoch 228/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1824 - info_loss: 44.5303 - class_loss: 1.0966 - IZY_bound: 2.2254 - IZX_bound: 44.5303 - Train acc: 0.5981 - val_acc: 0.6555 - val_loss: 0.9668\n",
            "Epoch 229/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1795 - info_loss: 44.6045 - class_loss: 1.0948 - IZY_bound: 2.2271 - IZX_bound: 44.6045 - Train acc: 0.6007 - val_acc: 0.6560 - val_loss: 0.9654\n",
            "Epoch 230/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1761 - info_loss: 44.8054 - class_loss: 1.0934 - IZY_bound: 2.2285 - IZX_bound: 44.8054 - Train acc: 0.6029 - val_acc: 0.6565 - val_loss: 0.9640\n",
            "Epoch 231/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1847 - info_loss: 44.7485 - class_loss: 1.0912 - IZY_bound: 2.2307 - IZX_bound: 44.7485 - Train acc: 0.5990 - val_acc: 0.6570 - val_loss: 0.9627\n",
            "Epoch 232/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1773 - info_loss: 44.7868 - class_loss: 1.0911 - IZY_bound: 2.2308 - IZX_bound: 44.7868 - Train acc: 0.6000 - val_acc: 0.6574 - val_loss: 0.9613\n",
            "Epoch 233/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1802 - info_loss: 44.5225 - class_loss: 1.0886 - IZY_bound: 2.2333 - IZX_bound: 44.5225 - Train acc: 0.5983 - val_acc: 0.6579 - val_loss: 0.9600\n",
            "Epoch 234/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1745 - info_loss: 44.7729 - class_loss: 1.0883 - IZY_bound: 2.2336 - IZX_bound: 44.7729 - Train acc: 0.6010 - val_acc: 0.6583 - val_loss: 0.9587\n",
            "Epoch 235/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1725 - info_loss: 45.1982 - class_loss: 1.0887 - IZY_bound: 2.2332 - IZX_bound: 45.1982 - Train acc: 0.6040 - val_acc: 0.6588 - val_loss: 0.9575\n",
            "Epoch 236/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1711 - info_loss: 44.7081 - class_loss: 1.0840 - IZY_bound: 2.2379 - IZX_bound: 44.7081 - Train acc: 0.6009 - val_acc: 0.6592 - val_loss: 0.9562\n",
            "Epoch 237/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1718 - info_loss: 45.0557 - class_loss: 1.0853 - IZY_bound: 2.2367 - IZX_bound: 45.0557 - Train acc: 0.6027 - val_acc: 0.6597 - val_loss: 0.9549\n",
            "Epoch 238/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1724 - info_loss: 45.0310 - class_loss: 1.0838 - IZY_bound: 2.2381 - IZX_bound: 45.0310 - Train acc: 0.6055 - val_acc: 0.6601 - val_loss: 0.9536\n",
            "Epoch 239/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1607 - info_loss: 44.5836 - class_loss: 1.0768 - IZY_bound: 2.2451 - IZX_bound: 44.5836 - Train acc: 0.6085 - val_acc: 0.6606 - val_loss: 0.9524\n",
            "Epoch 240/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1640 - info_loss: 44.9504 - class_loss: 1.0778 - IZY_bound: 2.2441 - IZX_bound: 44.9504 - Train acc: 0.6048 - val_acc: 0.6610 - val_loss: 0.9511\n",
            "Epoch 241/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1682 - info_loss: 45.0849 - class_loss: 1.0756 - IZY_bound: 2.2463 - IZX_bound: 45.0849 - Train acc: 0.6065 - val_acc: 0.6615 - val_loss: 0.9499\n",
            "Epoch 242/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1596 - info_loss: 44.8782 - class_loss: 1.0759 - IZY_bound: 2.2460 - IZX_bound: 44.8782 - Train acc: 0.6081 - val_acc: 0.6619 - val_loss: 0.9486\n",
            "Epoch 243/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1621 - info_loss: 45.3243 - class_loss: 1.0732 - IZY_bound: 2.2487 - IZX_bound: 45.3243 - Train acc: 0.6059 - val_acc: 0.6623 - val_loss: 0.9474\n",
            "Epoch 244/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1642 - info_loss: 44.9314 - class_loss: 1.0748 - IZY_bound: 2.2471 - IZX_bound: 44.9314 - Train acc: 0.6048 - val_acc: 0.6628 - val_loss: 0.9462\n",
            "Epoch 245/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1532 - info_loss: 44.9208 - class_loss: 1.0692 - IZY_bound: 2.2527 - IZX_bound: 44.9208 - Train acc: 0.6100 - val_acc: 0.6632 - val_loss: 0.9450\n",
            "Epoch 246/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1568 - info_loss: 44.8851 - class_loss: 1.0716 - IZY_bound: 2.2503 - IZX_bound: 44.8851 - Train acc: 0.6098 - val_acc: 0.6636 - val_loss: 0.9438\n",
            "Epoch 247/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1547 - info_loss: 44.8947 - class_loss: 1.0676 - IZY_bound: 2.2544 - IZX_bound: 44.8947 - Train acc: 0.6108 - val_acc: 0.6640 - val_loss: 0.9426\n",
            "Epoch 248/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1536 - info_loss: 44.9278 - class_loss: 1.0649 - IZY_bound: 2.2570 - IZX_bound: 44.9278 - Train acc: 0.6093 - val_acc: 0.6644 - val_loss: 0.9414\n",
            "Epoch 249/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1561 - info_loss: 45.1742 - class_loss: 1.0660 - IZY_bound: 2.2560 - IZX_bound: 45.1742 - Train acc: 0.6090 - val_acc: 0.6648 - val_loss: 0.9402\n",
            "Epoch 250/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.1540 - info_loss: 45.3913 - class_loss: 1.0678 - IZY_bound: 2.2542 - IZX_bound: 45.3913 - Train acc: 0.6080 - val_acc: 0.6653 - val_loss: 0.9390\n",
            "Epoch 251/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.1475 - info_loss: 45.2026 - class_loss: 1.0614 - IZY_bound: 2.2605 - IZX_bound: 45.2026 - Train acc: 0.6126 - val_acc: 0.6657 - val_loss: 0.9379\n",
            "Epoch 252/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1476 - info_loss: 45.2996 - class_loss: 1.0618 - IZY_bound: 2.2602 - IZX_bound: 45.2996 - Train acc: 0.6112 - val_acc: 0.6661 - val_loss: 0.9367\n",
            "Epoch 253/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.1493 - info_loss: 45.3332 - class_loss: 1.0574 - IZY_bound: 2.2645 - IZX_bound: 45.3332 - Train acc: 0.6124 - val_acc: 0.6665 - val_loss: 0.9356\n",
            "Epoch 254/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1411 - info_loss: 45.2509 - class_loss: 1.0562 - IZY_bound: 2.2657 - IZX_bound: 45.2509 - Train acc: 0.6151 - val_acc: 0.6669 - val_loss: 0.9344\n",
            "Epoch 255/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1488 - info_loss: 45.5217 - class_loss: 1.0575 - IZY_bound: 2.2644 - IZX_bound: 45.5217 - Train acc: 0.6103 - val_acc: 0.6673 - val_loss: 0.9333\n",
            "Epoch 256/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1460 - info_loss: 45.3913 - class_loss: 1.0533 - IZY_bound: 2.2686 - IZX_bound: 45.3913 - Train acc: 0.6137 - val_acc: 0.6677 - val_loss: 0.9322\n",
            "Epoch 257/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.1425 - info_loss: 45.3440 - class_loss: 1.0540 - IZY_bound: 2.2679 - IZX_bound: 45.3440 - Train acc: 0.6146 - val_acc: 0.6681 - val_loss: 0.9311\n",
            "Epoch 258/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1370 - info_loss: 45.6505 - class_loss: 1.0522 - IZY_bound: 2.2697 - IZX_bound: 45.6505 - Train acc: 0.6162 - val_acc: 0.6684 - val_loss: 0.9300\n",
            "Epoch 259/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1401 - info_loss: 45.8037 - class_loss: 1.0535 - IZY_bound: 2.2684 - IZX_bound: 45.8037 - Train acc: 0.6164 - val_acc: 0.6688 - val_loss: 0.9290\n",
            "Epoch 260/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1447 - info_loss: 45.5845 - class_loss: 1.0537 - IZY_bound: 2.2682 - IZX_bound: 45.5845 - Train acc: 0.6132 - val_acc: 0.6692 - val_loss: 0.9279\n",
            "Epoch 261/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.1348 - info_loss: 45.2595 - class_loss: 1.0477 - IZY_bound: 2.2742 - IZX_bound: 45.2595 - Train acc: 0.6184 - val_acc: 0.6696 - val_loss: 0.9268\n",
            "Epoch 262/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1310 - info_loss: 45.7844 - class_loss: 1.0458 - IZY_bound: 2.2761 - IZX_bound: 45.7844 - Train acc: 0.6191 - val_acc: 0.6699 - val_loss: 0.9259\n",
            "Epoch 263/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1354 - info_loss: 45.8476 - class_loss: 1.0457 - IZY_bound: 2.2763 - IZX_bound: 45.8476 - Train acc: 0.6163 - val_acc: 0.6703 - val_loss: 0.9248\n",
            "Epoch 264/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1298 - info_loss: 45.7557 - class_loss: 1.0456 - IZY_bound: 2.2764 - IZX_bound: 45.7557 - Train acc: 0.6197 - val_acc: 0.6706 - val_loss: 0.9238\n",
            "Epoch 265/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1303 - info_loss: 45.4725 - class_loss: 1.0421 - IZY_bound: 2.2798 - IZX_bound: 45.4725 - Train acc: 0.6185 - val_acc: 0.6710 - val_loss: 0.9228\n",
            "Epoch 266/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1345 - info_loss: 45.7198 - class_loss: 1.0439 - IZY_bound: 2.2780 - IZX_bound: 45.7198 - Train acc: 0.6179 - val_acc: 0.6714 - val_loss: 0.9217\n",
            "Epoch 267/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.1416 - info_loss: 45.8185 - class_loss: 1.0408 - IZY_bound: 2.2811 - IZX_bound: 45.8185 - Train acc: 0.6144 - val_acc: 0.6717 - val_loss: 0.9208\n",
            "Epoch 268/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1279 - info_loss: 45.6405 - class_loss: 1.0399 - IZY_bound: 2.2820 - IZX_bound: 45.6405 - Train acc: 0.6199 - val_acc: 0.6721 - val_loss: 0.9198\n",
            "Epoch 269/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1265 - info_loss: 45.8505 - class_loss: 1.0368 - IZY_bound: 2.2851 - IZX_bound: 45.8505 - Train acc: 0.6201 - val_acc: 0.6724 - val_loss: 0.9188\n",
            "Epoch 270/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1286 - info_loss: 45.9361 - class_loss: 1.0388 - IZY_bound: 2.2831 - IZX_bound: 45.9361 - Train acc: 0.6192 - val_acc: 0.6728 - val_loss: 0.9178\n",
            "Epoch 271/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.1270 - info_loss: 45.9002 - class_loss: 1.0348 - IZY_bound: 2.2871 - IZX_bound: 45.9002 - Train acc: 0.6195 - val_acc: 0.6731 - val_loss: 0.9169\n",
            "Epoch 272/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1201 - info_loss: 45.7067 - class_loss: 1.0340 - IZY_bound: 2.2879 - IZX_bound: 45.7067 - Train acc: 0.6220 - val_acc: 0.6735 - val_loss: 0.9159\n",
            "Epoch 273/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1197 - info_loss: 46.0601 - class_loss: 1.0348 - IZY_bound: 2.2872 - IZX_bound: 46.0601 - Train acc: 0.6216 - val_acc: 0.6738 - val_loss: 0.9150\n",
            "Epoch 274/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1158 - info_loss: 46.0675 - class_loss: 1.0320 - IZY_bound: 2.2899 - IZX_bound: 46.0675 - Train acc: 0.6251 - val_acc: 0.6741 - val_loss: 0.9140\n",
            "Epoch 275/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1132 - info_loss: 46.0419 - class_loss: 1.0282 - IZY_bound: 2.2937 - IZX_bound: 46.0419 - Train acc: 0.6248 - val_acc: 0.6745 - val_loss: 0.9131\n",
            "Epoch 276/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1144 - info_loss: 45.9295 - class_loss: 1.0275 - IZY_bound: 2.2945 - IZX_bound: 45.9295 - Train acc: 0.6241 - val_acc: 0.6748 - val_loss: 0.9123\n",
            "Epoch 277/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1202 - info_loss: 45.9564 - class_loss: 1.0263 - IZY_bound: 2.2956 - IZX_bound: 45.9564 - Train acc: 0.6217 - val_acc: 0.6751 - val_loss: 0.9113\n",
            "Epoch 278/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1147 - info_loss: 46.2797 - class_loss: 1.0302 - IZY_bound: 2.2918 - IZX_bound: 46.2797 - Train acc: 0.6230 - val_acc: 0.6754 - val_loss: 0.9104\n",
            "Epoch 279/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1119 - info_loss: 46.1155 - class_loss: 1.0240 - IZY_bound: 2.2980 - IZX_bound: 46.1155 - Train acc: 0.6247 - val_acc: 0.6758 - val_loss: 0.9095\n",
            "Epoch 280/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1125 - info_loss: 46.1379 - class_loss: 1.0246 - IZY_bound: 2.2974 - IZX_bound: 46.1379 - Train acc: 0.6261 - val_acc: 0.6761 - val_loss: 0.9086\n",
            "Epoch 281/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1236 - info_loss: 46.3540 - class_loss: 1.0250 - IZY_bound: 2.2969 - IZX_bound: 46.3540 - Train acc: 0.6198 - val_acc: 0.6764 - val_loss: 0.9078\n",
            "Epoch 282/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1078 - info_loss: 46.4111 - class_loss: 1.0216 - IZY_bound: 2.3003 - IZX_bound: 46.4111 - Train acc: 0.6260 - val_acc: 0.6767 - val_loss: 0.9069\n",
            "Epoch 283/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1107 - info_loss: 46.1240 - class_loss: 1.0182 - IZY_bound: 2.3037 - IZX_bound: 46.1240 - Train acc: 0.6243 - val_acc: 0.6770 - val_loss: 0.9061\n",
            "Epoch 284/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1046 - info_loss: 46.2993 - class_loss: 1.0186 - IZY_bound: 2.3033 - IZX_bound: 46.2993 - Train acc: 0.6273 - val_acc: 0.6773 - val_loss: 0.9052\n",
            "Epoch 285/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1114 - info_loss: 46.6867 - class_loss: 1.0175 - IZY_bound: 2.3044 - IZX_bound: 46.6867 - Train acc: 0.6243 - val_acc: 0.6777 - val_loss: 0.9044\n",
            "Epoch 286/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0964 - info_loss: 46.3277 - class_loss: 1.0153 - IZY_bound: 2.3066 - IZX_bound: 46.3277 - Train acc: 0.6311 - val_acc: 0.6780 - val_loss: 0.9035\n",
            "Epoch 287/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1006 - info_loss: 46.6566 - class_loss: 1.0133 - IZY_bound: 2.3086 - IZX_bound: 46.6566 - Train acc: 0.6290 - val_acc: 0.6783 - val_loss: 0.9027\n",
            "Epoch 288/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.1004 - info_loss: 46.2514 - class_loss: 1.0122 - IZY_bound: 2.3098 - IZX_bound: 46.2514 - Train acc: 0.6302 - val_acc: 0.6786 - val_loss: 0.9019\n",
            "Epoch 289/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0970 - info_loss: 46.4901 - class_loss: 1.0122 - IZY_bound: 2.3097 - IZX_bound: 46.4901 - Train acc: 0.6309 - val_acc: 0.6789 - val_loss: 0.9011\n",
            "Epoch 290/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1020 - info_loss: 46.9253 - class_loss: 1.0102 - IZY_bound: 2.3117 - IZX_bound: 46.9253 - Train acc: 0.6283 - val_acc: 0.6792 - val_loss: 0.9002\n",
            "Epoch 291/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.1064 - info_loss: 46.4909 - class_loss: 1.0098 - IZY_bound: 2.3122 - IZX_bound: 46.4909 - Train acc: 0.6272 - val_acc: 0.6795 - val_loss: 0.8994\n",
            "Epoch 292/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0985 - info_loss: 46.5160 - class_loss: 1.0090 - IZY_bound: 2.3130 - IZX_bound: 46.5160 - Train acc: 0.6298 - val_acc: 0.6797 - val_loss: 0.8986\n",
            "Epoch 293/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0986 - info_loss: 46.5006 - class_loss: 1.0065 - IZY_bound: 2.3154 - IZX_bound: 46.5006 - Train acc: 0.6300 - val_acc: 0.6800 - val_loss: 0.8978\n",
            "Epoch 294/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0926 - info_loss: 46.6823 - class_loss: 1.0055 - IZY_bound: 2.3165 - IZX_bound: 46.6823 - Train acc: 0.6301 - val_acc: 0.6803 - val_loss: 0.8970\n",
            "Epoch 295/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0962 - info_loss: 46.3228 - class_loss: 1.0059 - IZY_bound: 2.3160 - IZX_bound: 46.3228 - Train acc: 0.6299 - val_acc: 0.6806 - val_loss: 0.8962\n",
            "Epoch 296/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.1003 - info_loss: 46.6539 - class_loss: 1.0056 - IZY_bound: 2.3164 - IZX_bound: 46.6539 - Train acc: 0.6305 - val_acc: 0.6809 - val_loss: 0.8954\n",
            "Epoch 297/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0833 - info_loss: 46.8084 - class_loss: 1.0042 - IZY_bound: 2.3177 - IZX_bound: 46.8084 - Train acc: 0.6345 - val_acc: 0.6812 - val_loss: 0.8947\n",
            "Epoch 298/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0896 - info_loss: 46.8007 - class_loss: 1.0017 - IZY_bound: 2.3202 - IZX_bound: 46.8007 - Train acc: 0.6321 - val_acc: 0.6815 - val_loss: 0.8940\n",
            "Epoch 299/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0891 - info_loss: 46.7134 - class_loss: 1.0002 - IZY_bound: 2.3217 - IZX_bound: 46.7134 - Train acc: 0.6334 - val_acc: 0.6818 - val_loss: 0.8932\n",
            "Epoch 300/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0887 - info_loss: 46.6726 - class_loss: 1.0001 - IZY_bound: 2.3218 - IZX_bound: 46.6726 - Train acc: 0.6311 - val_acc: 0.6820 - val_loss: 0.8925\n",
            "Epoch 301/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0928 - info_loss: 46.9305 - class_loss: 0.9985 - IZY_bound: 2.3234 - IZX_bound: 46.9305 - Train acc: 0.6311 - val_acc: 0.6823 - val_loss: 0.8917\n",
            "Epoch 302/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.0928 - info_loss: 47.0033 - class_loss: 0.9987 - IZY_bound: 2.3232 - IZX_bound: 47.0033 - Train acc: 0.6305 - val_acc: 0.6826 - val_loss: 0.8910\n",
            "Epoch 303/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0856 - info_loss: 46.5850 - class_loss: 0.9924 - IZY_bound: 2.3296 - IZX_bound: 46.5850 - Train acc: 0.6342 - val_acc: 0.6828 - val_loss: 0.8903\n",
            "Epoch 304/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0844 - info_loss: 46.6944 - class_loss: 0.9943 - IZY_bound: 2.3276 - IZX_bound: 46.6944 - Train acc: 0.6345 - val_acc: 0.6831 - val_loss: 0.8897\n",
            "Epoch 305/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0921 - info_loss: 47.1310 - class_loss: 0.9952 - IZY_bound: 2.3268 - IZX_bound: 47.1310 - Train acc: 0.6296 - val_acc: 0.6833 - val_loss: 0.8889\n",
            "Epoch 306/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0798 - info_loss: 47.1375 - class_loss: 0.9922 - IZY_bound: 2.3297 - IZX_bound: 47.1375 - Train acc: 0.6336 - val_acc: 0.6836 - val_loss: 0.8882\n",
            "Epoch 307/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0809 - info_loss: 47.0853 - class_loss: 0.9930 - IZY_bound: 2.3289 - IZX_bound: 47.0853 - Train acc: 0.6369 - val_acc: 0.6839 - val_loss: 0.8875\n",
            "Epoch 308/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0743 - info_loss: 46.6563 - class_loss: 0.9882 - IZY_bound: 2.3337 - IZX_bound: 46.6563 - Train acc: 0.6391 - val_acc: 0.6842 - val_loss: 0.8868\n",
            "Epoch 309/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.0819 - info_loss: 47.4828 - class_loss: 0.9891 - IZY_bound: 2.3328 - IZX_bound: 47.4828 - Train acc: 0.6367 - val_acc: 0.6844 - val_loss: 0.8862\n",
            "Epoch 310/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0766 - info_loss: 46.9626 - class_loss: 0.9878 - IZY_bound: 2.3341 - IZX_bound: 46.9626 - Train acc: 0.6386 - val_acc: 0.6846 - val_loss: 0.8855\n",
            "Epoch 311/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0767 - info_loss: 47.3303 - class_loss: 0.9877 - IZY_bound: 2.3342 - IZX_bound: 47.3303 - Train acc: 0.6377 - val_acc: 0.6849 - val_loss: 0.8849\n",
            "Epoch 312/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0731 - info_loss: 47.0487 - class_loss: 0.9873 - IZY_bound: 2.3346 - IZX_bound: 47.0487 - Train acc: 0.6380 - val_acc: 0.6851 - val_loss: 0.8842\n",
            "Epoch 313/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0744 - info_loss: 47.1386 - class_loss: 0.9824 - IZY_bound: 2.3396 - IZX_bound: 47.1386 - Train acc: 0.6385 - val_acc: 0.6854 - val_loss: 0.8836\n",
            "Epoch 314/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0783 - info_loss: 47.1393 - class_loss: 0.9823 - IZY_bound: 2.3396 - IZX_bound: 47.1393 - Train acc: 0.6368 - val_acc: 0.6856 - val_loss: 0.8830\n",
            "Epoch 315/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0680 - info_loss: 47.1455 - class_loss: 0.9837 - IZY_bound: 2.3382 - IZX_bound: 47.1455 - Train acc: 0.6386 - val_acc: 0.6858 - val_loss: 0.8823\n",
            "Epoch 316/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0752 - info_loss: 47.3236 - class_loss: 0.9827 - IZY_bound: 2.3392 - IZX_bound: 47.3236 - Train acc: 0.6394 - val_acc: 0.6861 - val_loss: 0.8817\n",
            "Epoch 317/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0727 - info_loss: 47.7103 - class_loss: 0.9817 - IZY_bound: 2.3402 - IZX_bound: 47.7103 - Train acc: 0.6403 - val_acc: 0.6863 - val_loss: 0.8811\n",
            "Epoch 318/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0710 - info_loss: 47.2284 - class_loss: 0.9777 - IZY_bound: 2.3442 - IZX_bound: 47.2284 - Train acc: 0.6390 - val_acc: 0.6866 - val_loss: 0.8805\n",
            "Epoch 319/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0729 - info_loss: 47.4576 - class_loss: 0.9812 - IZY_bound: 2.3408 - IZX_bound: 47.4576 - Train acc: 0.6383 - val_acc: 0.6868 - val_loss: 0.8798\n",
            "Epoch 320/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0667 - info_loss: 47.2623 - class_loss: 0.9780 - IZY_bound: 2.3439 - IZX_bound: 47.2623 - Train acc: 0.6433 - val_acc: 0.6871 - val_loss: 0.8792\n",
            "Epoch 321/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0652 - info_loss: 47.1356 - class_loss: 0.9751 - IZY_bound: 2.3469 - IZX_bound: 47.1356 - Train acc: 0.6408 - val_acc: 0.6873 - val_loss: 0.8786\n",
            "Epoch 322/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0649 - info_loss: 47.2618 - class_loss: 0.9733 - IZY_bound: 2.3486 - IZX_bound: 47.2618 - Train acc: 0.6411 - val_acc: 0.6875 - val_loss: 0.8780\n",
            "Epoch 323/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.0618 - info_loss: 47.4550 - class_loss: 0.9719 - IZY_bound: 2.3500 - IZX_bound: 47.4550 - Train acc: 0.6419 - val_acc: 0.6877 - val_loss: 0.8774\n",
            "Epoch 324/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0628 - info_loss: 47.4887 - class_loss: 0.9711 - IZY_bound: 2.3508 - IZX_bound: 47.4887 - Train acc: 0.6426 - val_acc: 0.6880 - val_loss: 0.8768\n",
            "Epoch 325/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0640 - info_loss: 47.6668 - class_loss: 0.9723 - IZY_bound: 2.3496 - IZX_bound: 47.6668 - Train acc: 0.6431 - val_acc: 0.6882 - val_loss: 0.8762\n",
            "Epoch 326/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0662 - info_loss: 47.6993 - class_loss: 0.9709 - IZY_bound: 2.3510 - IZX_bound: 47.6993 - Train acc: 0.6394 - val_acc: 0.6884 - val_loss: 0.8757\n",
            "Epoch 327/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0644 - info_loss: 47.3582 - class_loss: 0.9711 - IZY_bound: 2.3508 - IZX_bound: 47.3582 - Train acc: 0.6408 - val_acc: 0.6886 - val_loss: 0.8751\n",
            "Epoch 328/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0652 - info_loss: 48.0285 - class_loss: 0.9708 - IZY_bound: 2.3512 - IZX_bound: 48.0285 - Train acc: 0.6418 - val_acc: 0.6889 - val_loss: 0.8745\n",
            "Epoch 329/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0574 - info_loss: 47.4642 - class_loss: 0.9671 - IZY_bound: 2.3548 - IZX_bound: 47.4642 - Train acc: 0.6421 - val_acc: 0.6891 - val_loss: 0.8740\n",
            "Epoch 330/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0602 - info_loss: 47.9294 - class_loss: 0.9670 - IZY_bound: 2.3549 - IZX_bound: 47.9294 - Train acc: 0.6436 - val_acc: 0.6893 - val_loss: 0.8734\n",
            "Epoch 331/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0654 - info_loss: 47.9021 - class_loss: 0.9671 - IZY_bound: 2.3548 - IZX_bound: 47.9021 - Train acc: 0.6398 - val_acc: 0.6895 - val_loss: 0.8728\n",
            "Epoch 332/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0593 - info_loss: 47.8537 - class_loss: 0.9676 - IZY_bound: 2.3544 - IZX_bound: 47.8537 - Train acc: 0.6431 - val_acc: 0.6898 - val_loss: 0.8722\n",
            "Epoch 333/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0579 - info_loss: 47.5695 - class_loss: 0.9643 - IZY_bound: 2.3576 - IZX_bound: 47.5695 - Train acc: 0.6436 - val_acc: 0.6900 - val_loss: 0.8716\n",
            "Epoch 334/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0494 - info_loss: 47.8940 - class_loss: 0.9631 - IZY_bound: 2.3588 - IZX_bound: 47.8940 - Train acc: 0.6475 - val_acc: 0.6902 - val_loss: 0.8711\n",
            "Epoch 335/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0490 - info_loss: 47.7676 - class_loss: 0.9602 - IZY_bound: 2.3617 - IZX_bound: 47.7676 - Train acc: 0.6486 - val_acc: 0.6904 - val_loss: 0.8706\n",
            "Epoch 336/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.0538 - info_loss: 47.7259 - class_loss: 0.9600 - IZY_bound: 2.3620 - IZX_bound: 47.7259 - Train acc: 0.6475 - val_acc: 0.6906 - val_loss: 0.8700\n",
            "Epoch 337/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0581 - info_loss: 48.0032 - class_loss: 0.9608 - IZY_bound: 2.3611 - IZX_bound: 48.0032 - Train acc: 0.6454 - val_acc: 0.6908 - val_loss: 0.8695\n",
            "Epoch 338/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0491 - info_loss: 47.7323 - class_loss: 0.9585 - IZY_bound: 2.3634 - IZX_bound: 47.7323 - Train acc: 0.6460 - val_acc: 0.6910 - val_loss: 0.8690\n",
            "Epoch 339/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0540 - info_loss: 47.9503 - class_loss: 0.9594 - IZY_bound: 2.3626 - IZX_bound: 47.9503 - Train acc: 0.6460 - val_acc: 0.6913 - val_loss: 0.8684\n",
            "Epoch 340/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0521 - info_loss: 47.8750 - class_loss: 0.9560 - IZY_bound: 2.3659 - IZX_bound: 47.8750 - Train acc: 0.6471 - val_acc: 0.6915 - val_loss: 0.8678\n",
            "Epoch 341/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0476 - info_loss: 47.9032 - class_loss: 0.9549 - IZY_bound: 2.3671 - IZX_bound: 47.9032 - Train acc: 0.6485 - val_acc: 0.6917 - val_loss: 0.8673\n",
            "Epoch 342/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0506 - info_loss: 48.0850 - class_loss: 0.9572 - IZY_bound: 2.3647 - IZX_bound: 48.0850 - Train acc: 0.6463 - val_acc: 0.6919 - val_loss: 0.8668\n",
            "Epoch 343/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0498 - info_loss: 48.1400 - class_loss: 0.9544 - IZY_bound: 2.3676 - IZX_bound: 48.1400 - Train acc: 0.6475 - val_acc: 0.6921 - val_loss: 0.8664\n",
            "Epoch 344/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0523 - info_loss: 48.1227 - class_loss: 0.9539 - IZY_bound: 2.3680 - IZX_bound: 48.1227 - Train acc: 0.6463 - val_acc: 0.6923 - val_loss: 0.8659\n",
            "Epoch 345/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0493 - info_loss: 48.0578 - class_loss: 0.9532 - IZY_bound: 2.3688 - IZX_bound: 48.0578 - Train acc: 0.6473 - val_acc: 0.6925 - val_loss: 0.8653\n",
            "Epoch 346/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0414 - info_loss: 47.7962 - class_loss: 0.9509 - IZY_bound: 2.3711 - IZX_bound: 47.7962 - Train acc: 0.6489 - val_acc: 0.6927 - val_loss: 0.8649\n",
            "Epoch 347/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0502 - info_loss: 48.2202 - class_loss: 0.9561 - IZY_bound: 2.3658 - IZX_bound: 48.2202 - Train acc: 0.6467 - val_acc: 0.6929 - val_loss: 0.8645\n",
            "Epoch 348/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0491 - info_loss: 48.0862 - class_loss: 0.9501 - IZY_bound: 2.3719 - IZX_bound: 48.0862 - Train acc: 0.6455 - val_acc: 0.6931 - val_loss: 0.8640\n",
            "Epoch 349/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0403 - info_loss: 48.3006 - class_loss: 0.9492 - IZY_bound: 2.3727 - IZX_bound: 48.3006 - Train acc: 0.6517 - val_acc: 0.6933 - val_loss: 0.8636\n",
            "Epoch 350/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.0359 - info_loss: 48.2462 - class_loss: 0.9458 - IZY_bound: 2.3761 - IZX_bound: 48.2462 - Train acc: 0.6506 - val_acc: 0.6935 - val_loss: 0.8631\n",
            "Epoch 351/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0388 - info_loss: 48.2592 - class_loss: 0.9438 - IZY_bound: 2.3781 - IZX_bound: 48.2592 - Train acc: 0.6513 - val_acc: 0.6937 - val_loss: 0.8626\n",
            "Epoch 352/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0441 - info_loss: 48.5406 - class_loss: 0.9457 - IZY_bound: 2.3763 - IZX_bound: 48.5406 - Train acc: 0.6496 - val_acc: 0.6939 - val_loss: 0.8622\n",
            "Epoch 353/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0349 - info_loss: 48.5875 - class_loss: 0.9434 - IZY_bound: 2.3785 - IZX_bound: 48.5875 - Train acc: 0.6528 - val_acc: 0.6940 - val_loss: 0.8617\n",
            "Epoch 354/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.0404 - info_loss: 48.5966 - class_loss: 0.9443 - IZY_bound: 2.3776 - IZX_bound: 48.5966 - Train acc: 0.6507 - val_acc: 0.6943 - val_loss: 0.8613\n",
            "Epoch 355/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0374 - info_loss: 48.3117 - class_loss: 0.9416 - IZY_bound: 2.3803 - IZX_bound: 48.3117 - Train acc: 0.6525 - val_acc: 0.6944 - val_loss: 0.8608\n",
            "Epoch 356/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0371 - info_loss: 48.4734 - class_loss: 0.9437 - IZY_bound: 2.3782 - IZX_bound: 48.4734 - Train acc: 0.6520 - val_acc: 0.6946 - val_loss: 0.8604\n",
            "Epoch 357/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0337 - info_loss: 48.2260 - class_loss: 0.9455 - IZY_bound: 2.3764 - IZX_bound: 48.2260 - Train acc: 0.6525 - val_acc: 0.6948 - val_loss: 0.8600\n",
            "Epoch 358/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0317 - info_loss: 48.6169 - class_loss: 0.9416 - IZY_bound: 2.3803 - IZX_bound: 48.6169 - Train acc: 0.6551 - val_acc: 0.6950 - val_loss: 0.8595\n",
            "Epoch 359/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0432 - info_loss: 48.7920 - class_loss: 0.9449 - IZY_bound: 2.3770 - IZX_bound: 48.7920 - Train acc: 0.6462 - val_acc: 0.6952 - val_loss: 0.8591\n",
            "Epoch 360/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0351 - info_loss: 48.3371 - class_loss: 0.9393 - IZY_bound: 2.3826 - IZX_bound: 48.3371 - Train acc: 0.6519 - val_acc: 0.6954 - val_loss: 0.8587\n",
            "Epoch 361/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0311 - info_loss: 48.4802 - class_loss: 0.9392 - IZY_bound: 2.3828 - IZX_bound: 48.4802 - Train acc: 0.6532 - val_acc: 0.6955 - val_loss: 0.8582\n",
            "Epoch 362/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0366 - info_loss: 48.3534 - class_loss: 0.9377 - IZY_bound: 2.3842 - IZX_bound: 48.3534 - Train acc: 0.6495 - val_acc: 0.6957 - val_loss: 0.8579\n",
            "Epoch 363/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0323 - info_loss: 48.7371 - class_loss: 0.9376 - IZY_bound: 2.3844 - IZX_bound: 48.7371 - Train acc: 0.6520 - val_acc: 0.6959 - val_loss: 0.8575\n",
            "Epoch 364/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0318 - info_loss: 48.8233 - class_loss: 0.9395 - IZY_bound: 2.3824 - IZX_bound: 48.8233 - Train acc: 0.6531 - val_acc: 0.6961 - val_loss: 0.8571\n",
            "Epoch 365/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0256 - info_loss: 48.3233 - class_loss: 0.9337 - IZY_bound: 2.3882 - IZX_bound: 48.3233 - Train acc: 0.6545 - val_acc: 0.6962 - val_loss: 0.8567\n",
            "Epoch 366/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0303 - info_loss: 48.4972 - class_loss: 0.9331 - IZY_bound: 2.3888 - IZX_bound: 48.4972 - Train acc: 0.6538 - val_acc: 0.6964 - val_loss: 0.8563\n",
            "Epoch 367/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0266 - info_loss: 48.5738 - class_loss: 0.9319 - IZY_bound: 2.3900 - IZX_bound: 48.5738 - Train acc: 0.6552 - val_acc: 0.6966 - val_loss: 0.8559\n",
            "Epoch 368/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0281 - info_loss: 48.7497 - class_loss: 0.9322 - IZY_bound: 2.3898 - IZX_bound: 48.7497 - Train acc: 0.6552 - val_acc: 0.6967 - val_loss: 0.8555\n",
            "Epoch 369/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0223 - info_loss: 48.6357 - class_loss: 0.9302 - IZY_bound: 2.3917 - IZX_bound: 48.6357 - Train acc: 0.6546 - val_acc: 0.6969 - val_loss: 0.8551\n",
            "Epoch 370/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0254 - info_loss: 48.4928 - class_loss: 0.9289 - IZY_bound: 2.3930 - IZX_bound: 48.4928 - Train acc: 0.6545 - val_acc: 0.6971 - val_loss: 0.8548\n",
            "Epoch 371/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0231 - info_loss: 48.9446 - class_loss: 0.9319 - IZY_bound: 2.3900 - IZX_bound: 48.9446 - Train acc: 0.6557 - val_acc: 0.6972 - val_loss: 0.8544\n",
            "Epoch 372/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0246 - info_loss: 49.0945 - class_loss: 0.9297 - IZY_bound: 2.3922 - IZX_bound: 49.0945 - Train acc: 0.6563 - val_acc: 0.6974 - val_loss: 0.8540\n",
            "Epoch 373/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0245 - info_loss: 49.0786 - class_loss: 0.9303 - IZY_bound: 2.3917 - IZX_bound: 49.0786 - Train acc: 0.6553 - val_acc: 0.6976 - val_loss: 0.8536\n",
            "Epoch 374/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0277 - info_loss: 49.2284 - class_loss: 0.9294 - IZY_bound: 2.3925 - IZX_bound: 49.2284 - Train acc: 0.6532 - val_acc: 0.6977 - val_loss: 0.8533\n",
            "Epoch 375/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0227 - info_loss: 49.2645 - class_loss: 0.9246 - IZY_bound: 2.3974 - IZX_bound: 49.2645 - Train acc: 0.6549 - val_acc: 0.6979 - val_loss: 0.8529\n",
            "Epoch 376/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0212 - info_loss: 49.2007 - class_loss: 0.9260 - IZY_bound: 2.3959 - IZX_bound: 49.2007 - Train acc: 0.6566 - val_acc: 0.6981 - val_loss: 0.8525\n",
            "Epoch 377/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0185 - info_loss: 48.8914 - class_loss: 0.9238 - IZY_bound: 2.3981 - IZX_bound: 48.8914 - Train acc: 0.6576 - val_acc: 0.6983 - val_loss: 0.8521\n",
            "Epoch 378/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0171 - info_loss: 49.0528 - class_loss: 0.9230 - IZY_bound: 2.3989 - IZX_bound: 49.0528 - Train acc: 0.6595 - val_acc: 0.6984 - val_loss: 0.8517\n",
            "Epoch 379/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0251 - info_loss: 49.2699 - class_loss: 0.9229 - IZY_bound: 2.3991 - IZX_bound: 49.2699 - Train acc: 0.6557 - val_acc: 0.6986 - val_loss: 0.8513\n",
            "Epoch 380/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0181 - info_loss: 48.7414 - class_loss: 0.9219 - IZY_bound: 2.4000 - IZX_bound: 48.7414 - Train acc: 0.6592 - val_acc: 0.6987 - val_loss: 0.8510\n",
            "Epoch 381/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0155 - info_loss: 48.9096 - class_loss: 0.9204 - IZY_bound: 2.4016 - IZX_bound: 48.9096 - Train acc: 0.6583 - val_acc: 0.6989 - val_loss: 0.8507\n",
            "Epoch 382/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0172 - info_loss: 49.1341 - class_loss: 0.9191 - IZY_bound: 2.4029 - IZX_bound: 49.1341 - Train acc: 0.6587 - val_acc: 0.6990 - val_loss: 0.8504\n",
            "Epoch 383/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0179 - info_loss: 49.3677 - class_loss: 0.9201 - IZY_bound: 2.4018 - IZX_bound: 49.3677 - Train acc: 0.6594 - val_acc: 0.6992 - val_loss: 0.8500\n",
            "Epoch 384/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0188 - info_loss: 49.2519 - class_loss: 0.9194 - IZY_bound: 2.4025 - IZX_bound: 49.2519 - Train acc: 0.6580 - val_acc: 0.6993 - val_loss: 0.8497\n",
            "Epoch 385/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0155 - info_loss: 49.4352 - class_loss: 0.9197 - IZY_bound: 2.4022 - IZX_bound: 49.4352 - Train acc: 0.6590 - val_acc: 0.6995 - val_loss: 0.8494\n",
            "Epoch 386/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0167 - info_loss: 49.4523 - class_loss: 0.9198 - IZY_bound: 2.4021 - IZX_bound: 49.4523 - Train acc: 0.6596 - val_acc: 0.6996 - val_loss: 0.8491\n",
            "Epoch 387/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0132 - info_loss: 49.3235 - class_loss: 0.9175 - IZY_bound: 2.4045 - IZX_bound: 49.3235 - Train acc: 0.6589 - val_acc: 0.6998 - val_loss: 0.8487\n",
            "Epoch 388/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0120 - info_loss: 49.0156 - class_loss: 0.9141 - IZY_bound: 2.4078 - IZX_bound: 49.0156 - Train acc: 0.6628 - val_acc: 0.7000 - val_loss: 0.8484\n",
            "Epoch 389/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0122 - info_loss: 49.2684 - class_loss: 0.9153 - IZY_bound: 2.4066 - IZX_bound: 49.2684 - Train acc: 0.6594 - val_acc: 0.7001 - val_loss: 0.8481\n",
            "Epoch 390/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0098 - info_loss: 49.3647 - class_loss: 0.9139 - IZY_bound: 2.4080 - IZX_bound: 49.3647 - Train acc: 0.6608 - val_acc: 0.7003 - val_loss: 0.8478\n",
            "Epoch 391/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0147 - info_loss: 49.6816 - class_loss: 0.9146 - IZY_bound: 2.4073 - IZX_bound: 49.6816 - Train acc: 0.6563 - val_acc: 0.7004 - val_loss: 0.8475\n",
            "Epoch 392/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0088 - info_loss: 49.3056 - class_loss: 0.9119 - IZY_bound: 2.4101 - IZX_bound: 49.3056 - Train acc: 0.6606 - val_acc: 0.7006 - val_loss: 0.8473\n",
            "Epoch 393/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0076 - info_loss: 49.3980 - class_loss: 0.9125 - IZY_bound: 2.4094 - IZX_bound: 49.3980 - Train acc: 0.6616 - val_acc: 0.7007 - val_loss: 0.8470\n",
            "Epoch 394/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0022 - info_loss: 49.3098 - class_loss: 0.9146 - IZY_bound: 2.4074 - IZX_bound: 49.3098 - Train acc: 0.6664 - val_acc: 0.7009 - val_loss: 0.8467\n",
            "Epoch 395/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0125 - info_loss: 49.6717 - class_loss: 0.9133 - IZY_bound: 2.4086 - IZX_bound: 49.6717 - Train acc: 0.6605 - val_acc: 0.7010 - val_loss: 0.8463\n",
            "Epoch 396/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0029 - info_loss: 49.2797 - class_loss: 0.9062 - IZY_bound: 2.4157 - IZX_bound: 49.2797 - Train acc: 0.6639 - val_acc: 0.7012 - val_loss: 0.8461\n",
            "Epoch 397/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0063 - info_loss: 49.4689 - class_loss: 0.9084 - IZY_bound: 2.4136 - IZX_bound: 49.4689 - Train acc: 0.6630 - val_acc: 0.7013 - val_loss: 0.8458\n",
            "Epoch 398/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0006 - info_loss: 49.4332 - class_loss: 0.9076 - IZY_bound: 2.4143 - IZX_bound: 49.4332 - Train acc: 0.6647 - val_acc: 0.7014 - val_loss: 0.8455\n",
            "Epoch 399/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0065 - info_loss: 49.5109 - class_loss: 0.9109 - IZY_bound: 2.4110 - IZX_bound: 49.5109 - Train acc: 0.6596 - val_acc: 0.7016 - val_loss: 0.8452\n",
            "Epoch 400/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0021 - info_loss: 49.5568 - class_loss: 0.9066 - IZY_bound: 2.4153 - IZX_bound: 49.5568 - Train acc: 0.6632 - val_acc: 0.7017 - val_loss: 0.8449\n",
            "Epoch 401/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 1.0053 - info_loss: 49.8924 - class_loss: 0.9069 - IZY_bound: 2.4150 - IZX_bound: 49.8924 - Train acc: 0.6607 - val_acc: 0.7019 - val_loss: 0.8446\n",
            "Epoch 402/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9988 - info_loss: 49.5298 - class_loss: 0.9031 - IZY_bound: 2.4188 - IZX_bound: 49.5298 - Train acc: 0.6652 - val_acc: 0.7020 - val_loss: 0.8444\n",
            "Epoch 403/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0000 - info_loss: 49.4585 - class_loss: 0.9041 - IZY_bound: 2.4178 - IZX_bound: 49.4585 - Train acc: 0.6648 - val_acc: 0.7022 - val_loss: 0.8441\n",
            "Epoch 404/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0035 - info_loss: 49.4696 - class_loss: 0.9021 - IZY_bound: 2.4199 - IZX_bound: 49.4696 - Train acc: 0.6629 - val_acc: 0.7023 - val_loss: 0.8438\n",
            "Epoch 405/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 1.0050 - info_loss: 49.8519 - class_loss: 0.9028 - IZY_bound: 2.4191 - IZX_bound: 49.8519 - Train acc: 0.6612 - val_acc: 0.7024 - val_loss: 0.8435\n",
            "Epoch 406/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9971 - info_loss: 49.8825 - class_loss: 0.9003 - IZY_bound: 2.4216 - IZX_bound: 49.8825 - Train acc: 0.6678 - val_acc: 0.7026 - val_loss: 0.8433\n",
            "Epoch 407/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9939 - info_loss: 49.9638 - class_loss: 0.8993 - IZY_bound: 2.4227 - IZX_bound: 49.9638 - Train acc: 0.6661 - val_acc: 0.7027 - val_loss: 0.8430\n",
            "Epoch 408/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 1.0002 - info_loss: 50.0281 - class_loss: 0.9014 - IZY_bound: 2.4206 - IZX_bound: 50.0281 - Train acc: 0.6641 - val_acc: 0.7028 - val_loss: 0.8427\n",
            "Epoch 409/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9934 - info_loss: 49.9964 - class_loss: 0.8999 - IZY_bound: 2.4220 - IZX_bound: 49.9964 - Train acc: 0.6664 - val_acc: 0.7030 - val_loss: 0.8425\n",
            "Epoch 410/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9902 - info_loss: 49.5784 - class_loss: 0.8971 - IZY_bound: 2.4248 - IZX_bound: 49.5784 - Train acc: 0.6668 - val_acc: 0.7031 - val_loss: 0.8423\n",
            "Epoch 411/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9934 - info_loss: 49.7342 - class_loss: 0.8969 - IZY_bound: 2.4250 - IZX_bound: 49.7342 - Train acc: 0.6659 - val_acc: 0.7032 - val_loss: 0.8420\n",
            "Epoch 412/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9996 - info_loss: 50.0845 - class_loss: 0.8971 - IZY_bound: 2.4248 - IZX_bound: 50.0845 - Train acc: 0.6640 - val_acc: 0.7034 - val_loss: 0.8418\n",
            "Epoch 413/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9935 - info_loss: 49.5684 - class_loss: 0.8963 - IZY_bound: 2.4257 - IZX_bound: 49.5684 - Train acc: 0.6662 - val_acc: 0.7035 - val_loss: 0.8416\n",
            "Epoch 414/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9909 - info_loss: 49.6105 - class_loss: 0.8958 - IZY_bound: 2.4261 - IZX_bound: 49.6105 - Train acc: 0.6682 - val_acc: 0.7036 - val_loss: 0.8414\n",
            "Epoch 415/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9989 - info_loss: 50.0245 - class_loss: 0.8955 - IZY_bound: 2.4264 - IZX_bound: 50.0245 - Train acc: 0.6630 - val_acc: 0.7037 - val_loss: 0.8412\n",
            "Epoch 416/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9923 - info_loss: 50.0727 - class_loss: 0.8969 - IZY_bound: 2.4250 - IZX_bound: 50.0727 - Train acc: 0.6668 - val_acc: 0.7039 - val_loss: 0.8410\n",
            "Epoch 417/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9910 - info_loss: 49.9434 - class_loss: 0.8931 - IZY_bound: 2.4288 - IZX_bound: 49.9434 - Train acc: 0.6650 - val_acc: 0.7040 - val_loss: 0.8407\n",
            "Epoch 418/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9933 - info_loss: 49.9872 - class_loss: 0.8919 - IZY_bound: 2.4300 - IZX_bound: 49.9872 - Train acc: 0.6661 - val_acc: 0.7041 - val_loss: 0.8405\n",
            "Epoch 419/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9981 - info_loss: 50.6854 - class_loss: 0.8968 - IZY_bound: 2.4252 - IZX_bound: 50.6854 - Train acc: 0.6635 - val_acc: 0.7042 - val_loss: 0.8404\n",
            "Epoch 420/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9936 - info_loss: 50.0812 - class_loss: 0.8924 - IZY_bound: 2.4296 - IZX_bound: 50.0812 - Train acc: 0.6673 - val_acc: 0.7043 - val_loss: 0.8401\n",
            "Epoch 421/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9898 - info_loss: 50.5468 - class_loss: 0.8906 - IZY_bound: 2.4313 - IZX_bound: 50.5468 - Train acc: 0.6687 - val_acc: 0.7045 - val_loss: 0.8399\n",
            "Epoch 422/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9879 - info_loss: 50.4105 - class_loss: 0.8920 - IZY_bound: 2.4299 - IZX_bound: 50.4105 - Train acc: 0.6669 - val_acc: 0.7046 - val_loss: 0.8397\n",
            "Epoch 423/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9851 - info_loss: 50.0295 - class_loss: 0.8909 - IZY_bound: 2.4310 - IZX_bound: 50.0295 - Train acc: 0.6676 - val_acc: 0.7047 - val_loss: 0.8395\n",
            "Epoch 424/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9907 - info_loss: 50.9899 - class_loss: 0.8910 - IZY_bound: 2.4309 - IZX_bound: 50.9899 - Train acc: 0.6673 - val_acc: 0.7048 - val_loss: 0.8393\n",
            "Epoch 425/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9765 - info_loss: 49.8540 - class_loss: 0.8842 - IZY_bound: 2.4377 - IZX_bound: 49.8540 - Train acc: 0.6741 - val_acc: 0.7050 - val_loss: 0.8391\n",
            "Epoch 426/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9879 - info_loss: 50.3389 - class_loss: 0.8884 - IZY_bound: 2.4335 - IZX_bound: 50.3389 - Train acc: 0.6695 - val_acc: 0.7051 - val_loss: 0.8388\n",
            "Epoch 427/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9838 - info_loss: 50.1597 - class_loss: 0.8870 - IZY_bound: 2.4350 - IZX_bound: 50.1597 - Train acc: 0.6683 - val_acc: 0.7052 - val_loss: 0.8387\n",
            "Epoch 428/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9827 - info_loss: 50.1933 - class_loss: 0.8832 - IZY_bound: 2.4387 - IZX_bound: 50.1933 - Train acc: 0.6697 - val_acc: 0.7053 - val_loss: 0.8385\n",
            "Epoch 429/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9846 - info_loss: 50.3549 - class_loss: 0.8828 - IZY_bound: 2.4391 - IZX_bound: 50.3549 - Train acc: 0.6707 - val_acc: 0.7054 - val_loss: 0.8383\n",
            "Epoch 430/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9803 - info_loss: 50.3337 - class_loss: 0.8867 - IZY_bound: 2.4352 - IZX_bound: 50.3337 - Train acc: 0.6694 - val_acc: 0.7055 - val_loss: 0.8381\n",
            "Epoch 431/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9769 - info_loss: 50.4896 - class_loss: 0.8839 - IZY_bound: 2.4380 - IZX_bound: 50.4896 - Train acc: 0.6699 - val_acc: 0.7057 - val_loss: 0.8379\n",
            "Epoch 432/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9769 - info_loss: 50.4447 - class_loss: 0.8823 - IZY_bound: 2.4396 - IZX_bound: 50.4447 - Train acc: 0.6697 - val_acc: 0.7058 - val_loss: 0.8377\n",
            "Epoch 433/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9872 - info_loss: 51.0542 - class_loss: 0.8861 - IZY_bound: 2.4358 - IZX_bound: 51.0542 - Train acc: 0.6694 - val_acc: 0.7059 - val_loss: 0.8375\n",
            "Epoch 434/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9799 - info_loss: 50.7328 - class_loss: 0.8793 - IZY_bound: 2.4426 - IZX_bound: 50.7328 - Train acc: 0.6720 - val_acc: 0.7060 - val_loss: 0.8374\n",
            "Epoch 435/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9798 - info_loss: 50.3731 - class_loss: 0.8791 - IZY_bound: 2.4428 - IZX_bound: 50.3731 - Train acc: 0.6730 - val_acc: 0.7061 - val_loss: 0.8372\n",
            "Epoch 436/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9794 - info_loss: 50.4846 - class_loss: 0.8795 - IZY_bound: 2.4424 - IZX_bound: 50.4846 - Train acc: 0.6709 - val_acc: 0.7062 - val_loss: 0.8370\n",
            "Epoch 437/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9785 - info_loss: 50.8012 - class_loss: 0.8792 - IZY_bound: 2.4427 - IZX_bound: 50.8012 - Train acc: 0.6717 - val_acc: 0.7063 - val_loss: 0.8368\n",
            "Epoch 438/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9789 - info_loss: 50.6759 - class_loss: 0.8819 - IZY_bound: 2.4400 - IZX_bound: 50.6759 - Train acc: 0.6704 - val_acc: 0.7064 - val_loss: 0.8367\n",
            "Epoch 439/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9740 - info_loss: 50.7339 - class_loss: 0.8755 - IZY_bound: 2.4464 - IZX_bound: 50.7339 - Train acc: 0.6751 - val_acc: 0.7066 - val_loss: 0.8365\n",
            "Epoch 440/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9708 - info_loss: 50.7701 - class_loss: 0.8773 - IZY_bound: 2.4446 - IZX_bound: 50.7701 - Train acc: 0.6733 - val_acc: 0.7067 - val_loss: 0.8363\n",
            "Epoch 441/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9700 - info_loss: 50.5716 - class_loss: 0.8746 - IZY_bound: 2.4473 - IZX_bound: 50.5716 - Train acc: 0.6750 - val_acc: 0.7068 - val_loss: 0.8362\n",
            "Epoch 442/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9720 - info_loss: 50.7971 - class_loss: 0.8744 - IZY_bound: 2.4476 - IZX_bound: 50.7971 - Train acc: 0.6744 - val_acc: 0.7069 - val_loss: 0.8360\n",
            "Epoch 443/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9737 - info_loss: 50.8284 - class_loss: 0.8775 - IZY_bound: 2.4444 - IZX_bound: 50.8284 - Train acc: 0.6719 - val_acc: 0.7070 - val_loss: 0.8358\n",
            "Epoch 444/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9848 - info_loss: 51.1860 - class_loss: 0.8788 - IZY_bound: 2.4431 - IZX_bound: 51.1860 - Train acc: 0.6688 - val_acc: 0.7071 - val_loss: 0.8357\n",
            "Epoch 445/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9783 - info_loss: 50.7445 - class_loss: 0.8749 - IZY_bound: 2.4470 - IZX_bound: 50.7445 - Train acc: 0.6723 - val_acc: 0.7072 - val_loss: 0.8356\n",
            "Epoch 446/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9710 - info_loss: 50.8186 - class_loss: 0.8729 - IZY_bound: 2.4490 - IZX_bound: 50.8186 - Train acc: 0.6741 - val_acc: 0.7073 - val_loss: 0.8354\n",
            "Epoch 447/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9665 - info_loss: 51.1411 - class_loss: 0.8728 - IZY_bound: 2.4491 - IZX_bound: 51.1411 - Train acc: 0.6770 - val_acc: 0.7074 - val_loss: 0.8352\n",
            "Epoch 448/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9671 - info_loss: 50.7532 - class_loss: 0.8705 - IZY_bound: 2.4514 - IZX_bound: 50.7532 - Train acc: 0.6765 - val_acc: 0.7075 - val_loss: 0.8351\n",
            "Epoch 449/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9702 - info_loss: 50.9185 - class_loss: 0.8696 - IZY_bound: 2.4524 - IZX_bound: 50.9185 - Train acc: 0.6753 - val_acc: 0.7076 - val_loss: 0.8349\n",
            "Epoch 450/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9670 - info_loss: 51.1805 - class_loss: 0.8713 - IZY_bound: 2.4506 - IZX_bound: 51.1805 - Train acc: 0.6769 - val_acc: 0.7078 - val_loss: 0.8347\n",
            "Epoch 451/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9624 - info_loss: 50.8636 - class_loss: 0.8690 - IZY_bound: 2.4529 - IZX_bound: 50.8636 - Train acc: 0.6781 - val_acc: 0.7079 - val_loss: 0.8346\n",
            "Epoch 452/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9684 - info_loss: 51.1407 - class_loss: 0.8726 - IZY_bound: 2.4493 - IZX_bound: 51.1407 - Train acc: 0.6758 - val_acc: 0.7080 - val_loss: 0.8345\n",
            "Epoch 453/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9710 - info_loss: 51.3719 - class_loss: 0.8714 - IZY_bound: 2.4505 - IZX_bound: 51.3719 - Train acc: 0.6717 - val_acc: 0.7081 - val_loss: 0.8344\n",
            "Epoch 454/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9685 - info_loss: 51.2332 - class_loss: 0.8662 - IZY_bound: 2.4558 - IZX_bound: 51.2332 - Train acc: 0.6761 - val_acc: 0.7082 - val_loss: 0.8342\n",
            "Epoch 455/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9630 - info_loss: 50.7078 - class_loss: 0.8661 - IZY_bound: 2.4558 - IZX_bound: 50.7078 - Train acc: 0.6773 - val_acc: 0.7083 - val_loss: 0.8341\n",
            "Epoch 456/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9709 - info_loss: 51.5158 - class_loss: 0.8692 - IZY_bound: 2.4528 - IZX_bound: 51.5158 - Train acc: 0.6767 - val_acc: 0.7084 - val_loss: 0.8340\n",
            "Epoch 457/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9660 - info_loss: 51.0701 - class_loss: 0.8662 - IZY_bound: 2.4558 - IZX_bound: 51.0701 - Train acc: 0.6760 - val_acc: 0.7085 - val_loss: 0.8339\n",
            "Epoch 458/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9598 - info_loss: 51.1072 - class_loss: 0.8636 - IZY_bound: 2.4584 - IZX_bound: 51.1072 - Train acc: 0.6774 - val_acc: 0.7086 - val_loss: 0.8337\n",
            "Epoch 459/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9599 - info_loss: 51.0688 - class_loss: 0.8646 - IZY_bound: 2.4573 - IZX_bound: 51.0688 - Train acc: 0.6778 - val_acc: 0.7087 - val_loss: 0.8336\n",
            "Epoch 460/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9648 - info_loss: 51.1408 - class_loss: 0.8650 - IZY_bound: 2.4569 - IZX_bound: 51.1408 - Train acc: 0.6756 - val_acc: 0.7088 - val_loss: 0.8335\n",
            "Epoch 461/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9648 - info_loss: 51.1041 - class_loss: 0.8619 - IZY_bound: 2.4600 - IZX_bound: 51.1041 - Train acc: 0.6769 - val_acc: 0.7089 - val_loss: 0.8334\n",
            "Epoch 462/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9652 - info_loss: 51.0706 - class_loss: 0.8646 - IZY_bound: 2.4573 - IZX_bound: 51.0706 - Train acc: 0.6769 - val_acc: 0.7089 - val_loss: 0.8333\n",
            "Epoch 463/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9691 - info_loss: 51.4441 - class_loss: 0.8622 - IZY_bound: 2.4597 - IZX_bound: 51.4441 - Train acc: 0.6748 - val_acc: 0.7090 - val_loss: 0.8332\n",
            "Epoch 464/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9603 - info_loss: 51.4008 - class_loss: 0.8602 - IZY_bound: 2.4617 - IZX_bound: 51.4008 - Train acc: 0.6784 - val_acc: 0.7091 - val_loss: 0.8331\n",
            "Epoch 465/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9612 - info_loss: 51.6078 - class_loss: 0.8629 - IZY_bound: 2.4590 - IZX_bound: 51.6078 - Train acc: 0.6765 - val_acc: 0.7092 - val_loss: 0.8329\n",
            "Epoch 466/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9589 - info_loss: 51.6195 - class_loss: 0.8628 - IZY_bound: 2.4592 - IZX_bound: 51.6195 - Train acc: 0.6790 - val_acc: 0.7093 - val_loss: 0.8328\n",
            "Epoch 467/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9597 - info_loss: 51.4956 - class_loss: 0.8599 - IZY_bound: 2.4621 - IZX_bound: 51.4956 - Train acc: 0.6779 - val_acc: 0.7094 - val_loss: 0.8327\n",
            "Epoch 468/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9591 - info_loss: 51.0757 - class_loss: 0.8570 - IZY_bound: 2.4649 - IZX_bound: 51.0757 - Train acc: 0.6785 - val_acc: 0.7095 - val_loss: 0.8326\n",
            "Epoch 469/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9618 - info_loss: 51.4857 - class_loss: 0.8606 - IZY_bound: 2.4613 - IZX_bound: 51.4857 - Train acc: 0.6773 - val_acc: 0.7096 - val_loss: 0.8325\n",
            "Epoch 470/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9618 - info_loss: 51.5061 - class_loss: 0.8571 - IZY_bound: 2.4648 - IZX_bound: 51.5061 - Train acc: 0.6765 - val_acc: 0.7097 - val_loss: 0.8324\n",
            "Epoch 471/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9564 - info_loss: 51.4187 - class_loss: 0.8565 - IZY_bound: 2.4654 - IZX_bound: 51.4187 - Train acc: 0.6797 - val_acc: 0.7098 - val_loss: 0.8323\n",
            "Epoch 472/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9565 - info_loss: 51.2412 - class_loss: 0.8562 - IZY_bound: 2.4657 - IZX_bound: 51.2412 - Train acc: 0.6802 - val_acc: 0.7099 - val_loss: 0.8322\n",
            "Epoch 473/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9603 - info_loss: 51.5876 - class_loss: 0.8549 - IZY_bound: 2.4670 - IZX_bound: 51.5876 - Train acc: 0.6782 - val_acc: 0.7100 - val_loss: 0.8321\n",
            "Epoch 474/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9590 - info_loss: 51.5494 - class_loss: 0.8550 - IZY_bound: 2.4669 - IZX_bound: 51.5494 - Train acc: 0.6776 - val_acc: 0.7101 - val_loss: 0.8320\n",
            "Epoch 475/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9533 - info_loss: 52.8209 - class_loss: 0.8553 - IZY_bound: 2.4666 - IZX_bound: 52.8209 - Train acc: 0.6809 - val_acc: 0.7102 - val_loss: 0.8319\n",
            "Epoch 476/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9544 - info_loss: 51.7634 - class_loss: 0.8559 - IZY_bound: 2.4660 - IZX_bound: 51.7634 - Train acc: 0.6788 - val_acc: 0.7102 - val_loss: 0.8319\n",
            "Epoch 477/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9556 - info_loss: 52.0716 - class_loss: 0.8534 - IZY_bound: 2.4685 - IZX_bound: 52.0716 - Train acc: 0.6804 - val_acc: 0.7103 - val_loss: 0.8318\n",
            "Epoch 478/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9498 - info_loss: 51.4667 - class_loss: 0.8520 - IZY_bound: 2.4699 - IZX_bound: 51.4667 - Train acc: 0.6801 - val_acc: 0.7104 - val_loss: 0.8317\n",
            "Epoch 479/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9518 - info_loss: 51.7039 - class_loss: 0.8515 - IZY_bound: 2.4705 - IZX_bound: 51.7039 - Train acc: 0.6795 - val_acc: 0.7105 - val_loss: 0.8316\n",
            "Epoch 480/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9505 - info_loss: 51.5990 - class_loss: 0.8519 - IZY_bound: 2.4700 - IZX_bound: 51.5990 - Train acc: 0.6812 - val_acc: 0.7106 - val_loss: 0.8315\n",
            "Epoch 481/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9493 - info_loss: 52.1133 - class_loss: 0.8498 - IZY_bound: 2.4722 - IZX_bound: 52.1133 - Train acc: 0.6835 - val_acc: 0.7107 - val_loss: 0.8314\n",
            "Epoch 482/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9544 - info_loss: 51.8166 - class_loss: 0.8503 - IZY_bound: 2.4716 - IZX_bound: 51.8166 - Train acc: 0.6795 - val_acc: 0.7107 - val_loss: 0.8314\n",
            "Epoch 483/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9489 - info_loss: 51.9505 - class_loss: 0.8499 - IZY_bound: 2.4720 - IZX_bound: 51.9505 - Train acc: 0.6808 - val_acc: 0.7108 - val_loss: 0.8313\n",
            "Epoch 484/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9473 - info_loss: 52.2835 - class_loss: 0.8496 - IZY_bound: 2.4723 - IZX_bound: 52.2835 - Train acc: 0.6818 - val_acc: 0.7109 - val_loss: 0.8313\n",
            "Epoch 485/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9509 - info_loss: 52.1543 - class_loss: 0.8465 - IZY_bound: 2.4754 - IZX_bound: 52.1543 - Train acc: 0.6797 - val_acc: 0.7110 - val_loss: 0.8312\n",
            "Epoch 486/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9525 - info_loss: 51.9670 - class_loss: 0.8507 - IZY_bound: 2.4712 - IZX_bound: 51.9670 - Train acc: 0.6820 - val_acc: 0.7111 - val_loss: 0.8311\n",
            "Epoch 487/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9495 - info_loss: 52.2815 - class_loss: 0.8479 - IZY_bound: 2.4740 - IZX_bound: 52.2815 - Train acc: 0.6829 - val_acc: 0.7112 - val_loss: 0.8310\n",
            "Epoch 488/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9502 - info_loss: 52.0663 - class_loss: 0.8490 - IZY_bound: 2.4729 - IZX_bound: 52.0663 - Train acc: 0.6804 - val_acc: 0.7112 - val_loss: 0.8309\n",
            "Epoch 489/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9466 - info_loss: 51.9926 - class_loss: 0.8447 - IZY_bound: 2.4772 - IZX_bound: 51.9926 - Train acc: 0.6846 - val_acc: 0.7113 - val_loss: 0.8309\n",
            "Epoch 490/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9477 - info_loss: 51.7659 - class_loss: 0.8444 - IZY_bound: 2.4775 - IZX_bound: 51.7659 - Train acc: 0.6826 - val_acc: 0.7114 - val_loss: 0.8308\n",
            "Epoch 491/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9492 - info_loss: 52.1977 - class_loss: 0.8478 - IZY_bound: 2.4741 - IZX_bound: 52.1977 - Train acc: 0.6815 - val_acc: 0.7115 - val_loss: 0.8307\n",
            "Epoch 492/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9473 - info_loss: 52.2540 - class_loss: 0.8442 - IZY_bound: 2.4777 - IZX_bound: 52.2540 - Train acc: 0.6811 - val_acc: 0.7116 - val_loss: 0.8306\n",
            "Epoch 493/10000\n",
            "108/108 [==============================] - 5s 50ms/step - loss: 0.9479 - info_loss: 51.9344 - class_loss: 0.8425 - IZY_bound: 2.4794 - IZX_bound: 51.9344 - Train acc: 0.6817 - val_acc: 0.7116 - val_loss: 0.8306\n",
            "Epoch 494/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9393 - info_loss: 52.3656 - class_loss: 0.8436 - IZY_bound: 2.4783 - IZX_bound: 52.3656 - Train acc: 0.6846 - val_acc: 0.7117 - val_loss: 0.8305\n",
            "Epoch 495/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9439 - info_loss: 52.0890 - class_loss: 0.8408 - IZY_bound: 2.4811 - IZX_bound: 52.0890 - Train acc: 0.6836 - val_acc: 0.7118 - val_loss: 0.8305\n",
            "Epoch 496/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9431 - info_loss: 52.4869 - class_loss: 0.8478 - IZY_bound: 2.4741 - IZX_bound: 52.4869 - Train acc: 0.6833 - val_acc: 0.7119 - val_loss: 0.8304\n",
            "Epoch 497/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9413 - info_loss: 52.2128 - class_loss: 0.8401 - IZY_bound: 2.4818 - IZX_bound: 52.2128 - Train acc: 0.6835 - val_acc: 0.7120 - val_loss: 0.8303\n",
            "Epoch 498/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9409 - info_loss: 52.3678 - class_loss: 0.8416 - IZY_bound: 2.4803 - IZX_bound: 52.3678 - Train acc: 0.6848 - val_acc: 0.7121 - val_loss: 0.8303\n",
            "Epoch 499/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9438 - info_loss: 52.6318 - class_loss: 0.8408 - IZY_bound: 2.4811 - IZX_bound: 52.6318 - Train acc: 0.6851 - val_acc: 0.7121 - val_loss: 0.8303\n",
            "Epoch 500/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9428 - info_loss: 52.3687 - class_loss: 0.8397 - IZY_bound: 2.4823 - IZX_bound: 52.3687 - Train acc: 0.6846 - val_acc: 0.7122 - val_loss: 0.8303\n",
            "Epoch 501/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9387 - info_loss: 52.6945 - class_loss: 0.8434 - IZY_bound: 2.4785 - IZX_bound: 52.6945 - Train acc: 0.6847 - val_acc: 0.7123 - val_loss: 0.8303\n",
            "Epoch 502/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9398 - info_loss: 52.6465 - class_loss: 0.8399 - IZY_bound: 2.4821 - IZX_bound: 52.6465 - Train acc: 0.6868 - val_acc: 0.7123 - val_loss: 0.8302\n",
            "Epoch 503/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9410 - info_loss: 52.6546 - class_loss: 0.8396 - IZY_bound: 2.4823 - IZX_bound: 52.6546 - Train acc: 0.6839 - val_acc: 0.7124 - val_loss: 0.8302\n",
            "Epoch 504/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9347 - info_loss: 52.1940 - class_loss: 0.8368 - IZY_bound: 2.4852 - IZX_bound: 52.1940 - Train acc: 0.6870 - val_acc: 0.7125 - val_loss: 0.8301\n",
            "Epoch 505/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9357 - info_loss: 52.5929 - class_loss: 0.8362 - IZY_bound: 2.4857 - IZX_bound: 52.5929 - Train acc: 0.6858 - val_acc: 0.7125 - val_loss: 0.8301\n",
            "Epoch 506/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9377 - info_loss: 52.6633 - class_loss: 0.8391 - IZY_bound: 2.4829 - IZX_bound: 52.6633 - Train acc: 0.6866 - val_acc: 0.7126 - val_loss: 0.8301\n",
            "Epoch 507/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9349 - info_loss: 52.4874 - class_loss: 0.8365 - IZY_bound: 2.4854 - IZX_bound: 52.4874 - Train acc: 0.6863 - val_acc: 0.7127 - val_loss: 0.8301\n",
            "Epoch 508/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9336 - info_loss: 52.6647 - class_loss: 0.8363 - IZY_bound: 2.4856 - IZX_bound: 52.6647 - Train acc: 0.6854 - val_acc: 0.7128 - val_loss: 0.8300\n",
            "Epoch 509/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9310 - info_loss: 52.6115 - class_loss: 0.8365 - IZY_bound: 2.4854 - IZX_bound: 52.6115 - Train acc: 0.6890 - val_acc: 0.7128 - val_loss: 0.8300\n",
            "Epoch 510/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9381 - info_loss: 52.4535 - class_loss: 0.8339 - IZY_bound: 2.4880 - IZX_bound: 52.4535 - Train acc: 0.6860 - val_acc: 0.7129 - val_loss: 0.8300\n",
            "Epoch 511/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9340 - info_loss: 52.6716 - class_loss: 0.8339 - IZY_bound: 2.4880 - IZX_bound: 52.6716 - Train acc: 0.6883 - val_acc: 0.7130 - val_loss: 0.8299\n",
            "Epoch 512/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9348 - info_loss: 52.8056 - class_loss: 0.8351 - IZY_bound: 2.4869 - IZX_bound: 52.8056 - Train acc: 0.6866 - val_acc: 0.7130 - val_loss: 0.8299\n",
            "Epoch 513/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9383 - info_loss: 52.8132 - class_loss: 0.8350 - IZY_bound: 2.4870 - IZX_bound: 52.8132 - Train acc: 0.6857 - val_acc: 0.7131 - val_loss: 0.8298\n",
            "Epoch 514/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9297 - info_loss: 52.5811 - class_loss: 0.8315 - IZY_bound: 2.4904 - IZX_bound: 52.5811 - Train acc: 0.6889 - val_acc: 0.7132 - val_loss: 0.8298\n",
            "Epoch 515/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9322 - info_loss: 52.5503 - class_loss: 0.8314 - IZY_bound: 2.4905 - IZX_bound: 52.5503 - Train acc: 0.6868 - val_acc: 0.7133 - val_loss: 0.8298\n",
            "Epoch 516/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9307 - info_loss: 52.5393 - class_loss: 0.8305 - IZY_bound: 2.4914 - IZX_bound: 52.5393 - Train acc: 0.6876 - val_acc: 0.7133 - val_loss: 0.8297\n",
            "Epoch 517/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9298 - info_loss: 52.8815 - class_loss: 0.8332 - IZY_bound: 2.4887 - IZX_bound: 52.8815 - Train acc: 0.6897 - val_acc: 0.7134 - val_loss: 0.8297\n",
            "Epoch 518/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9365 - info_loss: 52.5680 - class_loss: 0.8274 - IZY_bound: 2.4945 - IZX_bound: 52.5680 - Train acc: 0.6847 - val_acc: 0.7135 - val_loss: 0.8297\n",
            "Epoch 519/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9375 - info_loss: 52.8052 - class_loss: 0.8305 - IZY_bound: 2.4914 - IZX_bound: 52.8052 - Train acc: 0.6846 - val_acc: 0.7135 - val_loss: 0.8297\n",
            "Epoch 520/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9330 - info_loss: 52.8160 - class_loss: 0.8283 - IZY_bound: 2.4936 - IZX_bound: 52.8160 - Train acc: 0.6861 - val_acc: 0.7136 - val_loss: 0.8297\n",
            "Epoch 521/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9312 - info_loss: 52.8148 - class_loss: 0.8282 - IZY_bound: 2.4937 - IZX_bound: 52.8148 - Train acc: 0.6869 - val_acc: 0.7137 - val_loss: 0.8297\n",
            "Epoch 522/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9312 - info_loss: 53.0497 - class_loss: 0.8286 - IZY_bound: 2.4933 - IZX_bound: 53.0497 - Train acc: 0.6898 - val_acc: 0.7137 - val_loss: 0.8297\n",
            "Epoch 523/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9344 - info_loss: 52.7444 - class_loss: 0.8266 - IZY_bound: 2.4954 - IZX_bound: 52.7444 - Train acc: 0.6863 - val_acc: 0.7138 - val_loss: 0.8296\n",
            "Epoch 524/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9280 - info_loss: 53.3468 - class_loss: 0.8276 - IZY_bound: 2.4944 - IZX_bound: 53.3468 - Train acc: 0.6896 - val_acc: 0.7139 - val_loss: 0.8296\n",
            "Epoch 525/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9380 - info_loss: 52.9468 - class_loss: 0.8300 - IZY_bound: 2.4919 - IZX_bound: 52.9468 - Train acc: 0.6844 - val_acc: 0.7139 - val_loss: 0.8296\n",
            "Epoch 526/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9320 - info_loss: 52.6610 - class_loss: 0.8257 - IZY_bound: 2.4962 - IZX_bound: 52.6610 - Train acc: 0.6859 - val_acc: 0.7140 - val_loss: 0.8296\n",
            "Epoch 527/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9282 - info_loss: 53.2294 - class_loss: 0.8268 - IZY_bound: 2.4951 - IZX_bound: 53.2294 - Train acc: 0.6883 - val_acc: 0.7141 - val_loss: 0.8296\n",
            "Epoch 528/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9315 - info_loss: 53.3599 - class_loss: 0.8267 - IZY_bound: 2.4952 - IZX_bound: 53.3599 - Train acc: 0.6883 - val_acc: 0.7141 - val_loss: 0.8296\n",
            "Epoch 529/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9265 - info_loss: 52.6654 - class_loss: 0.8239 - IZY_bound: 2.4980 - IZX_bound: 52.6654 - Train acc: 0.6890 - val_acc: 0.7142 - val_loss: 0.8296\n",
            "Epoch 530/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9245 - info_loss: 53.1230 - class_loss: 0.8250 - IZY_bound: 2.4969 - IZX_bound: 53.1230 - Train acc: 0.6909 - val_acc: 0.7143 - val_loss: 0.8296\n",
            "Epoch 531/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9260 - info_loss: 52.9815 - class_loss: 0.8243 - IZY_bound: 2.4977 - IZX_bound: 52.9815 - Train acc: 0.6885 - val_acc: 0.7143 - val_loss: 0.8296\n",
            "Epoch 532/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9214 - info_loss: 53.0737 - class_loss: 0.8205 - IZY_bound: 2.5014 - IZX_bound: 53.0737 - Train acc: 0.6920 - val_acc: 0.7144 - val_loss: 0.8296\n",
            "Epoch 533/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9268 - info_loss: 53.2910 - class_loss: 0.8255 - IZY_bound: 2.4964 - IZX_bound: 53.2910 - Train acc: 0.6896 - val_acc: 0.7144 - val_loss: 0.8296\n",
            "Epoch 534/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9239 - info_loss: 53.0474 - class_loss: 0.8201 - IZY_bound: 2.5018 - IZX_bound: 53.0474 - Train acc: 0.6887 - val_acc: 0.7145 - val_loss: 0.8296\n",
            "Epoch 535/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9245 - info_loss: 53.1878 - class_loss: 0.8182 - IZY_bound: 2.5037 - IZX_bound: 53.1878 - Train acc: 0.6917 - val_acc: 0.7146 - val_loss: 0.8296\n",
            "Epoch 536/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9252 - info_loss: 53.3368 - class_loss: 0.8232 - IZY_bound: 2.4988 - IZX_bound: 53.3368 - Train acc: 0.6881 - val_acc: 0.7146 - val_loss: 0.8296\n",
            "Epoch 537/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9193 - info_loss: 53.2821 - class_loss: 0.8196 - IZY_bound: 2.5023 - IZX_bound: 53.2821 - Train acc: 0.6909 - val_acc: 0.7147 - val_loss: 0.8296\n",
            "Epoch 538/10000\n",
            "108/108 [==============================] - 5s 51ms/step - loss: 0.9219 - info_loss: 53.3484 - class_loss: 0.8217 - IZY_bound: 2.5003 - IZX_bound: 53.3484 - Train acc: 0.6891 - val_acc: 0.7148 - val_loss: 0.8296\n",
            "Epoch 539/10000\n",
            "108/108 [==============================] - 6s 51ms/step - loss: 0.9238 - info_loss: 53.4425 - class_loss: 0.8175 - IZY_bound: 2.5044 - IZX_bound: 53.4425 - Train acc: 0.6899 - val_acc: 0.7148 - val_loss: 0.8297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8clTRoz5z1YH",
        "outputId": "ce6b1b3c-0eff-4f14-e7ea-2c7a4011d693"
      },
      "source": [
        "vae = VAE()\n",
        "vae.load_weights('/content/drive/MyDrive/IB_checkpoints/checkpoint')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 2, 128)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 2, 128, 1)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 2, 128, 5)    0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 2, 126, 256)  4096        zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 2, 126, 256)  0           conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 2, 126, 260)  0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 1, 124, 80)   124880      zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 1, 124, 80)   0           conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 9920)         0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "mu (Dense)                      (None, 512)          5079552     flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_2 (Sli (None, 256)          0           mu[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_3 (Sli (None, 256)          0           mu[0][0]                         \n",
            "==================================================================================================\n",
            "Total params: 5,208,528\n",
            "Trainable params: 5,208,528\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 256)]             0         \n",
            "_________________________________________________________________\n",
            "dense3 (Dense)               (None, 11)                2827      \n",
            "=================================================================\n",
            "Total params: 2,827\n",
            "Trainable params: 2,827\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5d3e584550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUuGJBnywBjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6b4b80-fb2f-424d-d992-5cccfbcf93a6"
      },
      "source": [
        "Y_pred = np.argmax(vae(X_test[:10000]),axis=1)\n",
        "Y_test2 = np.argmax(Y_test,axis=1)\n",
        "co = 0\n",
        "for i in range(10000):\n",
        "  if(Y_test2[i]==Y_pred[i]):\n",
        "    co+=1\n",
        "print(co/10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef6MhrvuZo2H"
      },
      "source": [
        "# Show loss curves\n",
        "plt.figure()\n",
        "plt.title('Training performance')\n",
        "plt.plot(history.epoch, history.history['loss'], label='train loss+error')\n",
        "plt.plot(history.epoch, history.history['val_loss'], label='val_error')\n",
        "plt.legend()\n",
        "plt.savefig('%s Training performance' % (name))\n",
        "# plt.show()\n",
        "\n",
        "model.load_weights(filepath)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0, batch_size=batch_size)\n",
        "print('evaluate_score:', score)\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n",
        "    plt.figure()\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(labels))\n",
        "    plt.xticks(tick_marks, labels, rotation=45)\n",
        "    plt.yticks(tick_marks, labels)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.savefig(title)\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "# Plot confusion matrix\n",
        "test_Y_hat = model.predict(X_test, batch_size=batch_size)\n",
        "\n",
        "# %%č°ç¨ĺşäş§çćˇˇćˇçŠéľ\n",
        "pre_labels = []\n",
        "for x in test_Y_hat:\n",
        "    tmp = np.argmax(x, 0)\n",
        "    pre_labels.append(tmp)\n",
        "true_labels = []\n",
        "for x in Y_test:\n",
        "    tmp = np.argmax(x, 0)\n",
        "    true_labels.append(tmp)\n",
        "\n",
        "kappa = cohen_kappa_score(pre_labels, true_labels)\n",
        "oa = accuracy_score(true_labels, pre_labels)\n",
        "kappa_oa = {}\n",
        "print('oa_all:', oa)\n",
        "print('kappa_all:', kappa)\n",
        "kappa_oa['oa_all'] = oa\n",
        "kappa_oa['kappa_all'] = kappa\n",
        "fd = open('results_all_%s_d0.5.dat' % (name), 'wb')\n",
        "cPickle.dump((\"%s\" % (name), 0.5, kappa_oa), fd)\n",
        "fd.close()\n",
        "cnf_matrix = confusion_matrix(true_labels, pre_labels)\n",
        "# np.set_printoptions(precision=2)\n",
        "# Plot non-normalized confusion matrix\n",
        "# plt.figure()\n",
        "plotcm.plot_confusion_matrix(cnf_matrix, classes=classes,\n",
        "                             normalize=False,\n",
        "                             title='%s Confusion matrix, without normalization' % (name), showtext=True)\n",
        "plt.savefig('%s Confusion matrix, without normalization' % (name))\n",
        "# Plot normalized confusion matrix\n",
        "# plt.figure()\n",
        "plotcm.plot_confusion_matrix(cnf_matrix, classes=classes,\n",
        "                             normalize=True,\n",
        "                             title='%s Normalized confusion matrix' % (name), showtext=True)\n",
        "plt.savefig('%s Normalized confusion matrix' % (name))\n",
        "# plt.show()\n",
        "\n",
        "# %%čŞĺŽäšäş§çćˇˇćˇçŠéľ\n",
        "conf = np.zeros([len(classes), len(classes)])\n",
        "confnorm = np.zeros([len(classes), len(classes)])\n",
        "for i in range(0, X_test.shape[0]):\n",
        "    j = list(Y_test[i, :]).index(1)\n",
        "    k = int(np.argmax(test_Y_hat[i, :]))\n",
        "    conf[j, k] += 1\n",
        "for i in range(0, len(classes)):\n",
        "    confnorm[i, :] = conf[i, :] / np.sum(conf[i, :])\n",
        "plot_confusion_matrix(confnorm, labels=classes,\n",
        "                      title='%s Confusion matrix' % (name))\n",
        "\n",
        "# %%Plot confusion matrix çťĺž\n",
        "acc = {}\n",
        "kappa_dict = {}\n",
        "oa_dict = {}\n",
        "for snr in snrs:\n",
        "\n",
        "    # extract classes @ SNR\n",
        "    test_SNRs = list(map(lambda x: lbl[x][1], test_idx))\n",
        "    test_X_i = X_test[np.where(np.array(test_SNRs) == snr)]\n",
        "    test_Y_i = Y_test[np.where(np.array(test_SNRs) == snr)]\n",
        "\n",
        "    # estimate classes\n",
        "    test_Y_i_hat = model.predict(test_X_i)\n",
        "\n",
        "    # %%č°ç¨ĺşäş§çćˇˇćˇçŠéľ\n",
        "    pre_labels_i = []\n",
        "    for x in test_Y_i_hat:\n",
        "        tmp = np.argmax(x, 0)\n",
        "        pre_labels_i.append(tmp)\n",
        "    true_labels_i = []\n",
        "    for x in test_Y_i:\n",
        "        tmp = np.argmax(x, 0)\n",
        "        true_labels_i.append(tmp)\n",
        "    kappa = cohen_kappa_score(pre_labels_i, true_labels_i)\n",
        "    oa = accuracy_score(true_labels_i, pre_labels_i)\n",
        "    oa_dict[snr] = oa\n",
        "    kappa_dict[snr] = kappa\n",
        "    cnf_matrix = confusion_matrix(true_labels_i, pre_labels_i)\n",
        "    # np.set_printoptions(precision=2)\n",
        "    # Plot non-normalized confusion matrix\n",
        "    # plt.figure()\n",
        "    plotcm.plot_confusion_matrix(cnf_matrix, classes=classes,\n",
        "                                 normalize=False,\n",
        "                                 title='%s Confusion matrix, without normalization (SNR=%d)' % (name, snr), showtext=True)\n",
        "    plt.savefig('%s Confusion matrix, without normalization (SNR=%d)' %\n",
        "                (name, snr))\n",
        "    # Plot normalized confusion matrix\n",
        "    # plt.figure()\n",
        "    plotcm.plot_confusion_matrix(cnf_matrix, classes=classes,\n",
        "                                 normalize=True,\n",
        "                                 title='%s Normalized confusion matrix (SNR=%d)' % (name, snr), showtext=True)\n",
        "    plt.savefig('%s Normalized confusion matrix (SNR=%d)' % (name, snr))\n",
        "    # plt.show()\n",
        "\n",
        "    # %%čŞĺŽäšäş§çćˇˇćˇçŠéľ\n",
        "    conf = np.zeros([len(classes), len(classes)])\n",
        "    confnorm = np.zeros([len(classes), len(classes)])\n",
        "    for i in range(0, test_X_i.shape[0]):\n",
        "        j = list(test_Y_i[i, :]).index(1)\n",
        "        k = int(np.argmax(test_Y_i_hat[i, :]))\n",
        "        conf[j, k] += 1\n",
        "    for i in range(0, len(classes)):\n",
        "        confnorm[i, :] = conf[i, :] / np.sum(conf[i, :])\n",
        "    # plt.figure()\n",
        "    plot_confusion_matrix(confnorm, labels=classes,\n",
        "                          title=\"%s Confusion Matrix (SNR=%d)\" % (name, snr))\n",
        "\n",
        "    cor = np.sum(np.diag(conf))\n",
        "    ncor = np.sum(conf) - cor\n",
        "    print(\"Overall Accuracy: \", cor / (cor + ncor))\n",
        "    acc[snr] = 1.0 * cor / (cor + ncor)\n",
        "\n",
        "# %%Save results to a pickle file for plotting later\n",
        "print 'acc:', acc\n",
        "fd = open('results_%s_d0.5.dat' % (name), 'wb')\n",
        "cPickle.dump((\"%s\" % (name), 0.5, acc), fd)\n",
        "fd.close()\n",
        "print('oa:', oa_dict)\n",
        "fd = open('results_oa_%s_d0.5.dat' % (name), 'wb')\n",
        "cPickle.dump((\"%s\" % (name), 0.5, oa_dict), fd)\n",
        "fd.close()\n",
        "print('kappa:', kappa_dict)\n",
        "fd = open('results_kappa_%s_d0.5.dat' % (name), 'wb')\n",
        "cPickle.dump((\"%s\" % (name), 0.5, kappa_dict), fd)\n",
        "fd.close()\n",
        "\n",
        "# %%Plot accuracy curve\n",
        "plt.figure()\n",
        "plt.plot(snrs, list(map(lambda x: acc[x], snrs)))\n",
        "plt.xlabel(\"Signal to Noise Ratio\")\n",
        "plt.ylabel(\"Classification Accuracy\")\n",
        "plt.title(\"%s Classification Accuracy on RadioML 2016.10 Alpha\" % (name))\n",
        "plt.savefig(\"%s Classification Accuracy\" % (name))\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}